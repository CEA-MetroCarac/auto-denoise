{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Auto-Denoise","text":"<p>Auto-denoise (autoden) provides implementations for a small selection of unsupervised and self-supervised CNN denoising methods. These methods currently include: * Noise2Noise (N2N) - A self-supervised denoising method using pairs of images of the same object [1]. * Noise2Void (N2V) - A self-supervised denoising method capable of working with a single image [2]. We have also implemented a later development of the method that can work with structured noise [3]. * Deep Image Prior (DIP) - An unsupervised denoising/upsampling/deconvolution method that can also work with a single image [4].</p> <ul> <li>[1] Lehtinen, J., Munkberg, J., Hasselgren, J., Laine, S., Karras, T., Aittala, M., &amp; Aila, T. (2018). Noise2Noise: Learning Image Restoration without Clean Data. In J. Dy &amp; A. Krause (Eds.), Proceedings of the 35th International Conference on Machine Learning (Vol. 80, pp. 2965\u20132974). PMLR. https://proceedings.mlr.press/v80/lehtinen18a.html</li> <li>[2] Krull, A., Buchholz, T.-O., &amp; Jug, F. (2019). Noise2Void - Learning Denoising From Single Noisy Images. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2124\u20132132. https://doi.org/10.1109/CVPR.2019.00223</li> <li>[3] Broaddus, C., Krull, A., Weigert, M., Schmidt, U., &amp; Myers, G. (2020). Removing Structured Noise with Self-Supervised Blind-Spot Networks. 2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI), 159\u2013163. https://doi.org/10.1109/ISBI45749.2020.9098336</li> <li>[4] Lempitsky, V., Vedaldi, A., &amp; Ulyanov, D. (2018). Deep Image Prior. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 9446\u20139454. https://doi.org/10.1109/CVPR.2018.00984</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>It takes just a few steps to setup Auto-Denoise on your machine.</p>"},{"location":"#installing-with-conda","title":"Installing with conda","text":"<p>We recommend using Miniforge. Once installed <code>miniforge</code>, simply install <code>autoden</code> with: <pre><code>conda install auto-denoise -c n-vigano\n</code></pre></p>"},{"location":"#installing-from-pypi","title":"Installing from PyPI","text":"<p>Simply install with: <pre><code>python -m pip install auto-denoise\n</code></pre></p> <p>If you are on jupyter, and don't have the rights to install packages system-wide, then you can install with: <pre><code>! python -m pip install --user auto-denoise\n</code></pre></p>"},{"location":"#installing-from-source","title":"Installing from source","text":"<p>To install Auto-Denoise, simply clone this github.com project with either: <pre><code>git clone https://github.com/CEA-MetroCarac/auto-denoise.git auto-denoise\n</code></pre> or: <pre><code>git clone git@github.com:CEA-MetroCarac/auto-denoise.git auto-denoise\n</code></pre></p> <p>Then go to the cloned directory and run <code>pip</code> installer: <pre><code>cd auto-denoise\npip install -e .\n</code></pre></p>"},{"location":"#how-to-contribute","title":"How to contribute","text":"<p>Contributions are always welcome. Please submit pull requests against the <code>main</code> branch.</p> <p>If you have any issues, questions, or remarks, then please open an issue on github.com.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"code_of_conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"code_of_conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall   community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of   any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address,   without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"code_of_conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"code_of_conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at nicola.vigano@cea.fr. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"code_of_conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"code_of_conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"code_of_conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"code_of_conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"code_of_conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"code_of_conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p>"},{"location":"contributing/#environment-setup","title":"Environment setup","text":"<p>Nothing easier!</p> <p>Fork and clone the repository, then:</p> <pre><code>cd auto-denoise\nmake setup\n</code></pre> <p>NOTE: If it fails for some reason, you'll need to install uv manually.</p> <p>You can install it with:</p> <pre><code>python3 -m pip install --user pipx\npipx install uv\n</code></pre> <p>Now you can try running <code>make setup</code> again, or simply <code>uv install</code>.</p> <p>You now have the dependencies installed.</p> <p>You can run the application with <code>make run autoden [ARGS...]</code>.</p> <p>Run <code>make help</code> to see all the available actions!</p>"},{"location":"contributing/#tasks","title":"Tasks","text":"<p>This project uses duty to run tasks. A Makefile is also provided. The Makefile will try to run certain tasks on multiple Python versions. If for some reason you don't want to run the task on multiple Python versions, you run the task directly with <code>make run duty TASK</code>.</p> <p>The Makefile detects if a virtual environment is activated, so <code>make</code> will work the same with the virtualenv activated or not.</p> <p>If you work in VSCode, we provide an action to configure VSCode for the project.</p>"},{"location":"contributing/#development","title":"Development","text":"<p>As usual:</p> <ol> <li>create a new branch: <code>git switch -c feature-or-bugfix-name</code></li> <li>edit the code and/or the documentation</li> </ol> <p>Before committing:</p> <ol> <li>run <code>make format</code> to auto-format the code</li> <li>run <code>make check</code> to check everything (fix any warning)</li> <li>run <code>make test</code> to run the tests (fix any issue)</li> <li>if you updated the documentation or the project dependencies:<ol> <li>run <code>make docs</code></li> <li>go to http://localhost:8000 and check that everything looks good</li> </ol> </li> <li>follow our commit message convention</li> </ol> <p>If you are unsure about how to fix or ignore a warning, just let the continuous integration fail, and we will help you during review.</p> <p>Don't bother updating the changelog, we will take care of this.</p>"},{"location":"contributing/#commit-message-convention","title":"Commit message convention","text":"<p>Commit messages must follow our convention based on the Angular style or the Karma convention:</p> <pre><code>&lt;type&gt;[(scope)]: Subject\n\n[Body]\n</code></pre> <p>Subject and body must be valid Markdown. Subject must have proper casing (uppercase for first letter if it makes sense), but no dot at the end, and no punctuation in general.</p> <p>Scope and body are optional. Type can be:</p> <ul> <li><code>build</code>: About packaging, building wheels, etc.</li> <li><code>chore</code>: About packaging or repo/files management.</li> <li><code>ci</code>: About Continuous Integration.</li> <li><code>deps</code>: Dependencies update.</li> <li><code>docs</code>: About documentation.</li> <li><code>feat</code>: New feature.</li> <li><code>fix</code>: Bug fix.</li> <li><code>perf</code>: About performance.</li> <li><code>refactor</code>: Changes that are not features or bug fixes.</li> <li><code>style</code>: A change in code style/format.</li> <li><code>tests</code>: About tests.</li> </ul> <p>If you write a body, please add trailers at the end (for example issues and PR references, or co-authors), without relying on GitHub's flavored Markdown:</p> <pre><code>Body.\n\nIssue #10: https://github.com/namespace/project/issues/10\nRelated to PR namespace/other-project#15: https://github.com/namespace/other-project/pull/15\n</code></pre> <p>These \"trailers\" must appear at the end of the body, without any blank lines between them. The trailer title can contain any character except colons <code>:</code>. We expect a full URI for each trailer, not just GitHub autolinks (for example, full GitHub URLs for commits and issues, not the hash or the #issue-number).</p> <p>We do not enforce a line length on commit messages summary and body, but please avoid very long summaries, and very long lines in the body, unless they are part of code blocks that must not be wrapped.</p>"},{"location":"contributing/#pull-requests-guidelines","title":"Pull requests guidelines","text":"<p>Link to any related issue in the Pull Request message.</p> <p>During the review, we recommend using fixups:</p> <pre><code># SHA is the SHA of the commit you want to fix\ngit commit --fixup=SHA\n</code></pre> <p>Once all the changes are approved, you can squash your commits:</p> <pre><code>git rebase -i --autosquash main\n</code></pre> <p>And force-push:</p> <pre><code>git push -f\n</code></pre> <p>If this seems all too complicated, you can push or force-push each new commit, and we will squash them ourselves if needed, before merging.</p>"},{"location":"credits/","title":"Credits","text":"<p>```python exec=\"yes\" \"\"\"Script to generate the project's credits.\"\"\"</p> <p>from future import annotations</p> <p>import os import sys from collections import defaultdict from importlib.metadata import distributions from itertools import chain from pathlib import Path from textwrap import dedent from typing import Dict, Iterable, Union</p> <p>from jinja2 import StrictUndefined from jinja2.sandbox import SandboxedEnvironment from packaging.requirements import Requirement</p>"},{"location":"credits/#todo-remove-once-support-for-python-310-is-dropped","title":"TODO: Remove once support for Python 3.10 is dropped.","text":"<p>if sys.version_info &gt;= (3, 11):     import tomllib else:     import tomli as tomllib</p> <p>project_dir = Path(os.getenv(\"MKDOCS_CONFIG_DIR\", \".\")) with project_dir.joinpath(\"pyproject.toml\").open(\"rb\") as pyproject_file:     pyproject = tomllib.load(pyproject_file) project = pyproject[\"project\"] project_name = project[\"name\"] devdeps = [line.strip() for line in project[\"optional-dependencies\"][\"dev\"]] devdeps = [line for line in devdeps if line and not line.startswith((\"-e\", \"#\")) and line != \"\"]</p>"},{"location":"credits/#with-project_dirjoinpathrequirements-devtxtopen-as-devdeps_file","title":"with project_dir.joinpath(\"requirements-dev.txt\").open() as devdeps_file:","text":""},{"location":"credits/#devdeps-linestrip-for-line-in-devdeps_file-if-linestrip-and-not-linestripstartswith-e","title":"devdeps = [line.strip() for line in devdeps_file if line.strip() and not line.strip().startswith((\"-e\", \"#\"))]","text":"<p>PackageMetadata = Dict[str, Union[str, Iterable[str]]] Metadata = Dict[str, PackageMetadata]</p> <p>def _merge_fields(metadata: dict) -&gt; PackageMetadata:     fields = defaultdict(list)     for header, value in metadata.items():         fields[header.lower()].append(value.strip())     return {         field: value if len(value) &gt; 1 or field in (\"classifier\", \"requires-dist\") else value[0]         for field, value in fields.items()     }</p> <p>def norm_name(name: str) -&gt; str:     return name.replace(\"\", \"-\").replace(\".\", \"-\").lower()</p> <p>def _requirements(deps: list[str]) -&gt; dict[str, Requirement]:     return {_norm_name((req := Requirement(dep)).name): req for dep in deps}</p> <p>def _extra_marker(req: Requirement) -&gt; str | None:     if not req.marker:         return None     try:         return next(marker[2].value for marker in req.marker._markers if getattr(marker[0], \"value\", None) == \"extra\")     except StopIteration:         return None</p> <p>def _get_metadata() -&gt; Metadata:     metadata = {}     for pkg in distributions():         name = _norm_name(pkg.name)  # type: ignore[attr-defined,unused-ignore]         metadata[name] = _merge_fields(pkg.metadata)  # type: ignore[arg-type]         metadata[name][\"spec\"] = set()         metadata[name][\"extras\"] = set()         metadata[name].setdefault(\"summary\", \"\")         _set_license(metadata[name])     return metadata</p> <p>def _set_license(metadata: PackageMetadata) -&gt; None:     license_field = metadata.get(\"license-expression\", metadata.get(\"license\", \"\"))     license_name = license_field if isinstance(license_field, str) else \" + \".join(license_field)     check_classifiers = license_name in (\"UNKNOWN\", \"Dual License\", \"\") or license_name.count(\"\\n\")     if check_classifiers:         license_names = []         for classifier in metadata[\"classifier\"]:             if classifier.startswith(\"License ::\"):                 license_names.append(classifier.rsplit(\"::\", 1)[1].strip())         license_name = \" + \".join(license_names)     metadata[\"license\"] = license_name or \"?\"</p> <p>def _get_deps(base_deps: dict[str, Requirement], metadata: Metadata) -&gt; Metadata:     deps = {}     for dep_name, dep_req in base_deps.items():         if dep_name not in metadata or dep_name == \"auto-denoise\":             continue         metadata[dep_name][\"spec\"] |= {str(spec) for spec in dep_req.specifier}  # type: ignore[operator]         metadata[dep_name][\"extras\"] |= dep_req.extras  # type: ignore[operator]         deps[dep_name] = metadata[dep_name]</p> <pre><code>again = True\nwhile again:\n    again = False\n    for pkg_name in metadata:\n        if pkg_name in deps:\n            for pkg_dependency in metadata[pkg_name].get(\"requires-dist\", []):\n                requirement = Requirement(pkg_dependency)\n                dep_name = _norm_name(requirement.name)\n                extra_marker = _extra_marker(requirement)\n                if (\n                    dep_name in metadata\n                    and dep_name not in deps\n                    and dep_name != project[\"name\"]\n                    and (not extra_marker or extra_marker in deps[pkg_name][\"extras\"])\n                ):\n                    metadata[dep_name][\"spec\"] |= {str(spec) for spec in requirement.specifier}  # type: ignore[operator]\n                    deps[dep_name] = metadata[dep_name]\n                    again = True\n\nreturn deps\n</code></pre> <p>def _render_credits() -&gt; str:     metadata = _get_metadata()     dev_dependencies = _get_deps(_requirements(devdeps), metadata)     prod_dependencies = _get_deps(         _requirements(             chain(  # type: ignore[arg-type]                 project.get(\"dependencies\", []),                 chain(*project.get(\"optional-dependencies\", {}).values()),             ),         ),         metadata,     )</p> <pre><code>template_data = {\n    \"project_name\": project_name,\n    \"prod_dependencies\": sorted(prod_dependencies.values(), key=lambda dep: str(dep[\"name\"]).lower()),\n    \"dev_dependencies\": sorted(dev_dependencies.values(), key=lambda dep: str(dep[\"name\"]).lower()),\n    \"more_credits\": \"\",\n}\ntemplate_text = dedent(\n    \"\"\"\n    # Credits\n\n    These projects were used to build *{{ project_name }}*. **Thank you!**\n\n    [Python](https://www.python.org/) |\n    [uv](https://github.com/astral-sh/uv) |\n    [copier-uv](https://github.com/pawamoy/copier-uv)\n\n    {% macro dep_line(dep) -%}\n    [{{ dep.name }}](https://pypi.org/project/{{ dep.name }}/) | {{ dep.summary }} | {{ (\"`\" ~ dep.spec|sort(reverse=True)|join(\", \") ~ \"`\") if dep.spec else \"\" }} | `{{ dep.version }}` | {{ dep.license }}\n    {%- endmacro %}\n\n    {% if prod_dependencies -%}\n    ### Runtime dependencies\n\n    Project | Summary | Version (accepted) | Version (last resolved) | License\n    ------- | ------- | ------------------ | ----------------------- | -------\n    {% for dep in prod_dependencies -%}\n    {{ dep_line(dep) }}\n    {% endfor %}\n\n    {% endif -%}\n    {% if dev_dependencies -%}\n    ### Development dependencies\n\n    Project | Summary | Version (accepted) | Version (last resolved) | License\n    ------- | ------- | ------------------ | ----------------------- | -------\n    {% for dep in dev_dependencies -%}\n    {{ dep_line(dep) }}\n    {% endfor %}\n\n    {% endif -%}\n    {% if more_credits %}**[More credits from the author]({{ more_credits }})**{% endif %}\n    \"\"\",\n)\njinja_env = SandboxedEnvironment(undefined=StrictUndefined)\nreturn jinja_env.from_string(template_text).render(**template_data)\n</code></pre> <p>print(_render_credits())</p> <p>```</p>"},{"location":"license/","title":"License","text":"<pre><code>MIT License\n\nCopyright (c) 2023 Nicola VIGANO\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li> autoden<ul> <li> algorithms</li> <li> cli</li> <li> debug</li> <li> io</li> <li> losses</li> <li> models<ul> <li> config</li> <li> dncnn</li> <li> msd</li> <li> param_utils</li> <li> unet</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/autoden/","title":"autoden","text":""},{"location":"reference/autoden/#autoden","title":"autoden","text":"<p>Auto-Denoise package.</p> <p>Unsupervised and self-supervised CNN denoising methods.</p> <p>Modules:</p> <ul> <li> <code>algorithms</code>           \u2013            <p>Implementation of various unsupervised and self-supervised denoising methods.</p> </li> <li> <code>cli</code>           \u2013            <p>Module that contains the command line application.</p> </li> <li> <code>debug</code>           \u2013            <p>Debugging utilities.</p> </li> <li> <code>io</code>           \u2013            <p>IO module.</p> </li> <li> <code>losses</code>           \u2013            <p>Data losses definitions.</p> </li> <li> <code>models</code>           \u2013            <p>Models sub-package.</p> </li> </ul> <p>Classes:</p> <ul> <li> <code>DIP</code>           \u2013            <p>Deep image prior.</p> </li> <li> <code>DataScalingBias</code>           \u2013            <p>Data scaling and bias.</p> </li> <li> <code>Denoiser</code>           \u2013            <p>Denoising images.</p> </li> <li> <code>N2N</code>           \u2013            <p>Self-supervised denoising from pairs of images.</p> </li> <li> <code>N2V</code>           \u2013            <p>Self-supervised denoising from single images.</p> </li> <li> <code>NetworkParams</code>           \u2013            <p>Abstract base class for storing network parameters.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>compute_scaling_selfsupervised</code>             \u2013              <p>Compute input data scaling and bias for self-supervised learning.</p> </li> <li> <code>compute_scaling_supervised</code>             \u2013              <p>Compute input and target data scaling and bias for supervised learning.</p> </li> <li> <code>create_network</code>             \u2013              <p>Create and return a neural network model based on the provided network configuration.</p> </li> <li> <code>create_optimizer</code>             \u2013              <p>Instantiates the desired optimizer for the given model.</p> </li> <li> <code>fix_invalid_gradient_values</code>             \u2013              <p>Fixes invalid gradient values in the model's parameters.</p> </li> <li> <code>get_num_parameters</code>             \u2013              <p>Returns the number of trainable parameters in the model.</p> </li> <li> <code>load_model_state</code>             \u2013              <p>Load a model from disk.</p> </li> <li> <code>save_model_state</code>             \u2013              <p>Save a model's state to disk.</p> </li> </ul>"},{"location":"reference/autoden/#autoden.DIP","title":"DIP","text":"<pre><code>DIP(model: int | str | NetworkParams | Module | Mapping, data_scaling_bias: DataScalingBias | None = None, reg_tv_val: float | None = 1e-05, device: str = 'cuda' if is_available() else 'cpu', save_epochs_dir: str | None = None, verbose: bool = True)\n</code></pre> <p>               Bases: <code>Denoiser</code></p> <p>Deep image prior.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str | NetworkParams | Module | Mapping | None</code>)           \u2013            <p>Type of neural network to use or a specific network (or state) to use</p> </li> <li> <code>data_scaling_bias</code>               (<code>DataScalingBias | None</code>, default:                   <code>None</code> )           \u2013            <p>Scaling and bias of the input data, by default None</p> </li> <li> <code>reg_tv_val</code>               (<code>float | None</code>, default:                   <code>1e-05</code> )           \u2013            <p>Deep-image prior regularization value, by default 1e-5</p> </li> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"</p> </li> <li> <code>save_epochs_dir</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Directory where to save network states at each epoch. If None disabled, by default None</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to produce verbose output, by default True</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>infer</code>             \u2013              <p>Inference, given an initial stack of images.</p> </li> <li> <code>train_supervised</code>             \u2013              <p>Supervised training.</p> </li> <li> <code>train_unsupervised</code>             \u2013              <p>Train the model in an unsupervised manner.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def __init__(\n    self,\n    model: int | str | NetworkParams | pt.nn.Module | Mapping,\n    data_scaling_bias: DataScalingBias | None = None,\n    reg_tv_val: float | None = 1e-5,\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n    save_epochs_dir: str | None = None,\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"Initialize the noise2noise method.\n\n    Parameters\n    ----------\n    model : str | NetworkParams | pt.nn.Module | Mapping | None\n        Type of neural network to use or a specific network (or state) to use\n    data_scaling_bias : DataScalingBias | None, optional\n        Scaling and bias of the input data, by default None\n    reg_tv_val : float | None, optional\n        Deep-image prior regularization value, by default 1e-5\n    device : str, optional\n        Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"\n    save_epochs_dir : str | None, optional\n        Directory where to save network states at each epoch.\n        If None disabled, by default None\n    verbose : bool, optional\n        Whether to produce verbose output, by default True\n    \"\"\"\n    if isinstance(model, int):\n        if self.save_epochs_dir is None:\n            raise ValueError(\"Directory for saving epochs not specified\")\n\n        model = load_model_state(self.save_epochs_dir, epoch_num=model)\n\n    if isinstance(model, (str, NetworkParams, Mapping, pt.nn.Module)):\n        self.model = create_network(model, device=device)\n    else:\n        raise ValueError(f\"Invalid model {type(model)}\")\n    if verbose:\n        get_num_parameters(self.model, verbose=True)\n\n    self.data_sb = data_scaling_bias\n\n    self.reg_val = reg_tv_val\n    self.device = device\n    self.save_epochs_dir = save_epochs_dir\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/autoden/#autoden.DIP.infer","title":"infer","text":"<pre><code>infer(inp: NDArray) -&gt; NDArray\n</code></pre> <p>Inference, given an initial stack of images.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input stack of images</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>The denoised stack of images</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def infer(self, inp: NDArray) -&gt; NDArray:\n    \"\"\"Inference, given an initial stack of images.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input stack of images\n\n    Returns\n    -------\n    NDArray\n        The denoised stack of images\n    \"\"\"\n    # Rescale input\n    if self.data_sb is not None:\n        inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n\n    inp_t = _single_channel_imgs_to_tensor(inp, device=self.device)\n\n    self.model.eval()\n    with pt.inference_mode():\n        out_t: pt.Tensor = self.model(inp_t)\n        output = out_t.to(\"cpu\").numpy().reshape(inp.shape)\n\n    # Rescale output\n    if self.data_sb is not None:\n        output = (output + self.data_sb.bias_out) / self.data_sb.scaling_out\n\n    return output\n</code></pre>"},{"location":"reference/autoden/#autoden.DIP.train_supervised","title":"train_supervised","text":"<pre><code>train_supervised(inp: NDArray, tgt: NDArray, epochs: int, tst_inds: Sequence[int] | NDArray, algo: str = 'adam')\n</code></pre> <p>Supervised training.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input images</p> </li> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>The target images</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>Number of training epochs</p> </li> <li> <code>tst_inds</code>               (<code>Sequence[int] | NDArray</code>)           \u2013            <p>The validation set indices</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>Learning algorithm to use, by default \"adam\"</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_supervised(\n    self,\n    inp: NDArray,\n    tgt: NDArray,\n    epochs: int,\n    tst_inds: Sequence[int] | NDArray,\n    algo: str = \"adam\",\n):\n    \"\"\"Supervised training.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input images\n    tgt : NDArray\n        The target images\n    epochs : int\n        Number of training epochs\n    tst_inds : Sequence[int] | NDArray\n        The validation set indices\n    algo : str, optional\n        Learning algorithm to use, by default \"adam\"\n    \"\"\"\n    num_imgs = inp.shape[0]\n    tst_inds = np.array(tst_inds, dtype=int)\n    if np.any(tst_inds &lt; 0) or np.any(tst_inds &gt;= num_imgs):\n        raise ValueError(\n            f\"Each cross-validation index should be greater or equal than 0, and less than the number of images {num_imgs}\"\n        )\n    trn_inds = np.delete(np.arange(num_imgs), obj=tst_inds)\n\n    if tgt.ndim == (inp.ndim - 1):\n        tgt = np.tile(tgt[None, ...], [num_imgs, *np.ones_like(tgt.shape)])\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_supervised(inp, tgt)\n\n    # Rescale the datasets\n    inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n    tgt = tgt * self.data_sb.scaling_tgt - self.data_sb.bias_tgt\n\n    # Create datasets\n    dset_trn = (inp[trn_inds], tgt[trn_inds])\n    dset_tst = (inp[tst_inds], tgt[tst_inds])\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    loss_trn, loss_tst = self._train_selfsimilar(dset_trn, dset_tst, epochs=epochs, algo=algo, regularizer=reg)\n\n    if self.verbose:\n        self._plot_loss_curves(loss_trn, loss_tst, f\"Supervised {algo.upper()}\")\n</code></pre>"},{"location":"reference/autoden/#autoden.DIP.train_unsupervised","title":"train_unsupervised","text":"<pre><code>train_unsupervised(tgt: NDArray, epochs: int, inp: NDArray | None = None, num_tst_ratio: float = 0.2, algo: str = 'adam') -&gt; NDArray\n</code></pre> <p>Train the model in an unsupervised manner.</p> <p>Parameters:</p> <ul> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>The target image to be denoised.</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>The number of training epochs.</p> </li> <li> <code>inp</code>               (<code>NDArray | None</code>, default:                   <code>None</code> )           \u2013            <p>The input image. If None, a random image will be generated. Default is None.</p> </li> <li> <code>num_tst_ratio</code>               (<code>float</code>, default:                   <code>0.2</code> )           \u2013            <p>The ratio of the test set size to the total dataset size. Default is 0.2.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>The optimization algorithm to use. Default is \"adam\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>The denoised input image.</p> </li> </ul> Notes <p>This method trains the model using the deep image prior approach in an unsupervised manner. It uses a random initialization for the input image if not provided and applies a scaling and bias transformation to the input and target images. It then splits the data into training and test sets based on the provided ratio and trains the model using the specified optimization algorithm.</p> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_unsupervised(\n    self, tgt: NDArray, epochs: int, inp: NDArray | None = None, num_tst_ratio: float = 0.2, algo: str = \"adam\"\n) -&gt; NDArray:\n    \"\"\"\n    Train the model in an unsupervised manner.\n\n    Parameters\n    ----------\n    tgt : NDArray\n        The target image to be denoised.\n    epochs : int\n        The number of training epochs.\n    inp : NDArray | None, optional\n        The input image. If None, a random image will be generated.\n        Default is None.\n    num_tst_ratio : float, optional\n        The ratio of the test set size to the total dataset size.\n        Default is 0.2.\n    algo : str, optional\n        The optimization algorithm to use. Default is \"adam\".\n\n    Returns\n    -------\n    NDArray\n        The denoised input image.\n\n    Notes\n    -----\n    This method trains the model using the deep image prior approach in an unsupervised manner.\n    It uses a random initialization for the input image if not provided and applies a scaling and bias\n    transformation to the input and target images. It then splits the data into training and test sets\n    based on the provided ratio and trains the model using the specified optimization algorithm.\n    \"\"\"\n    if inp is None:\n        inp = np.random.normal(size=tgt.shape[-2:], scale=0.25).astype(tgt.dtype)\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_supervised(inp, tgt)\n\n    # Rescale the datasets\n    tmp_inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n    tmp_tgt = tgt * self.data_sb.scaling_tgt - self.data_sb.bias_tgt\n\n    mask_trn = np.ones_like(tgt, dtype=bool)\n    rnd_inds = np.random.random_integers(low=0, high=mask_trn.size - 1, size=int(mask_trn.size * num_tst_ratio))\n    mask_trn[np.unravel_index(rnd_inds, shape=mask_trn.shape)] = False\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    losses_trn, losses_tst = self._train_pixelmask_small(\n        tmp_inp, tmp_tgt, mask_trn, epochs=epochs, algo=algo, regularizer=reg\n    )\n\n    if self.verbose:\n        self._plot_loss_curves(losses_trn, losses_tst, f\"Unsupervised {self.__class__.__name__} {algo.upper()}\")\n\n    return inp\n</code></pre>"},{"location":"reference/autoden/#autoden.DataScalingBias","title":"DataScalingBias  <code>dataclass</code>","text":"<pre><code>DataScalingBias(scaling_inp: float | NDArray = 1.0, scaling_out: float | NDArray = 1.0, scaling_tgt: float | NDArray = 1.0, bias_inp: float | NDArray = 0.0, bias_out: float | NDArray = 0.0, bias_tgt: float | NDArray = 0.0)\n</code></pre> <p>Data scaling and bias.</p>"},{"location":"reference/autoden/#autoden.Denoiser","title":"Denoiser","text":"<pre><code>Denoiser(model: int | str | NetworkParams | Module | Mapping, data_scaling_bias: DataScalingBias | None = None, reg_tv_val: float | None = 1e-05, device: str = 'cuda' if is_available() else 'cpu', save_epochs_dir: str | None = None, verbose: bool = True)\n</code></pre> <p>Denoising images.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str | NetworkParams | Module | Mapping | None</code>)           \u2013            <p>Type of neural network to use or a specific network (or state) to use</p> </li> <li> <code>data_scaling_bias</code>               (<code>DataScalingBias | None</code>, default:                   <code>None</code> )           \u2013            <p>Scaling and bias of the input data, by default None</p> </li> <li> <code>reg_tv_val</code>               (<code>float | None</code>, default:                   <code>1e-05</code> )           \u2013            <p>Deep-image prior regularization value, by default 1e-5</p> </li> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"</p> </li> <li> <code>save_epochs_dir</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Directory where to save network states at each epoch. If None disabled, by default None</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to produce verbose output, by default True</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>infer</code>             \u2013              <p>Inference, given an initial stack of images.</p> </li> <li> <code>train_supervised</code>             \u2013              <p>Supervised training.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def __init__(\n    self,\n    model: int | str | NetworkParams | pt.nn.Module | Mapping,\n    data_scaling_bias: DataScalingBias | None = None,\n    reg_tv_val: float | None = 1e-5,\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n    save_epochs_dir: str | None = None,\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"Initialize the noise2noise method.\n\n    Parameters\n    ----------\n    model : str | NetworkParams | pt.nn.Module | Mapping | None\n        Type of neural network to use or a specific network (or state) to use\n    data_scaling_bias : DataScalingBias | None, optional\n        Scaling and bias of the input data, by default None\n    reg_tv_val : float | None, optional\n        Deep-image prior regularization value, by default 1e-5\n    device : str, optional\n        Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"\n    save_epochs_dir : str | None, optional\n        Directory where to save network states at each epoch.\n        If None disabled, by default None\n    verbose : bool, optional\n        Whether to produce verbose output, by default True\n    \"\"\"\n    if isinstance(model, int):\n        if self.save_epochs_dir is None:\n            raise ValueError(\"Directory for saving epochs not specified\")\n\n        model = load_model_state(self.save_epochs_dir, epoch_num=model)\n\n    if isinstance(model, (str, NetworkParams, Mapping, pt.nn.Module)):\n        self.model = create_network(model, device=device)\n    else:\n        raise ValueError(f\"Invalid model {type(model)}\")\n    if verbose:\n        get_num_parameters(self.model, verbose=True)\n\n    self.data_sb = data_scaling_bias\n\n    self.reg_val = reg_tv_val\n    self.device = device\n    self.save_epochs_dir = save_epochs_dir\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/autoden/#autoden.Denoiser.infer","title":"infer","text":"<pre><code>infer(inp: NDArray) -&gt; NDArray\n</code></pre> <p>Inference, given an initial stack of images.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input stack of images</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>The denoised stack of images</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def infer(self, inp: NDArray) -&gt; NDArray:\n    \"\"\"Inference, given an initial stack of images.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input stack of images\n\n    Returns\n    -------\n    NDArray\n        The denoised stack of images\n    \"\"\"\n    # Rescale input\n    if self.data_sb is not None:\n        inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n\n    inp_t = _single_channel_imgs_to_tensor(inp, device=self.device)\n\n    self.model.eval()\n    with pt.inference_mode():\n        out_t: pt.Tensor = self.model(inp_t)\n        output = out_t.to(\"cpu\").numpy().reshape(inp.shape)\n\n    # Rescale output\n    if self.data_sb is not None:\n        output = (output + self.data_sb.bias_out) / self.data_sb.scaling_out\n\n    return output\n</code></pre>"},{"location":"reference/autoden/#autoden.Denoiser.train_supervised","title":"train_supervised","text":"<pre><code>train_supervised(inp: NDArray, tgt: NDArray, epochs: int, tst_inds: Sequence[int] | NDArray, algo: str = 'adam')\n</code></pre> <p>Supervised training.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input images</p> </li> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>The target images</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>Number of training epochs</p> </li> <li> <code>tst_inds</code>               (<code>Sequence[int] | NDArray</code>)           \u2013            <p>The validation set indices</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>Learning algorithm to use, by default \"adam\"</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_supervised(\n    self,\n    inp: NDArray,\n    tgt: NDArray,\n    epochs: int,\n    tst_inds: Sequence[int] | NDArray,\n    algo: str = \"adam\",\n):\n    \"\"\"Supervised training.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input images\n    tgt : NDArray\n        The target images\n    epochs : int\n        Number of training epochs\n    tst_inds : Sequence[int] | NDArray\n        The validation set indices\n    algo : str, optional\n        Learning algorithm to use, by default \"adam\"\n    \"\"\"\n    num_imgs = inp.shape[0]\n    tst_inds = np.array(tst_inds, dtype=int)\n    if np.any(tst_inds &lt; 0) or np.any(tst_inds &gt;= num_imgs):\n        raise ValueError(\n            f\"Each cross-validation index should be greater or equal than 0, and less than the number of images {num_imgs}\"\n        )\n    trn_inds = np.delete(np.arange(num_imgs), obj=tst_inds)\n\n    if tgt.ndim == (inp.ndim - 1):\n        tgt = np.tile(tgt[None, ...], [num_imgs, *np.ones_like(tgt.shape)])\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_supervised(inp, tgt)\n\n    # Rescale the datasets\n    inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n    tgt = tgt * self.data_sb.scaling_tgt - self.data_sb.bias_tgt\n\n    # Create datasets\n    dset_trn = (inp[trn_inds], tgt[trn_inds])\n    dset_tst = (inp[tst_inds], tgt[tst_inds])\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    loss_trn, loss_tst = self._train_selfsimilar(dset_trn, dset_tst, epochs=epochs, algo=algo, regularizer=reg)\n\n    if self.verbose:\n        self._plot_loss_curves(loss_trn, loss_tst, f\"Supervised {algo.upper()}\")\n</code></pre>"},{"location":"reference/autoden/#autoden.N2N","title":"N2N","text":"<pre><code>N2N(model: int | str | NetworkParams | Module | Mapping, data_scaling_bias: DataScalingBias | None = None, reg_tv_val: float | None = 1e-05, device: str = 'cuda' if is_available() else 'cpu', save_epochs_dir: str | None = None, verbose: bool = True)\n</code></pre> <p>               Bases: <code>Denoiser</code></p> <p>Self-supervised denoising from pairs of images.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str | NetworkParams | Module | Mapping | None</code>)           \u2013            <p>Type of neural network to use or a specific network (or state) to use</p> </li> <li> <code>data_scaling_bias</code>               (<code>DataScalingBias | None</code>, default:                   <code>None</code> )           \u2013            <p>Scaling and bias of the input data, by default None</p> </li> <li> <code>reg_tv_val</code>               (<code>float | None</code>, default:                   <code>1e-05</code> )           \u2013            <p>Deep-image prior regularization value, by default 1e-5</p> </li> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"</p> </li> <li> <code>save_epochs_dir</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Directory where to save network states at each epoch. If None disabled, by default None</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to produce verbose output, by default True</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>infer</code>             \u2013              <p>Inference, given an initial stack of images.</p> </li> <li> <code>train_supervised</code>             \u2013              <p>Supervised training.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def __init__(\n    self,\n    model: int | str | NetworkParams | pt.nn.Module | Mapping,\n    data_scaling_bias: DataScalingBias | None = None,\n    reg_tv_val: float | None = 1e-5,\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n    save_epochs_dir: str | None = None,\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"Initialize the noise2noise method.\n\n    Parameters\n    ----------\n    model : str | NetworkParams | pt.nn.Module | Mapping | None\n        Type of neural network to use or a specific network (or state) to use\n    data_scaling_bias : DataScalingBias | None, optional\n        Scaling and bias of the input data, by default None\n    reg_tv_val : float | None, optional\n        Deep-image prior regularization value, by default 1e-5\n    device : str, optional\n        Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"\n    save_epochs_dir : str | None, optional\n        Directory where to save network states at each epoch.\n        If None disabled, by default None\n    verbose : bool, optional\n        Whether to produce verbose output, by default True\n    \"\"\"\n    if isinstance(model, int):\n        if self.save_epochs_dir is None:\n            raise ValueError(\"Directory for saving epochs not specified\")\n\n        model = load_model_state(self.save_epochs_dir, epoch_num=model)\n\n    if isinstance(model, (str, NetworkParams, Mapping, pt.nn.Module)):\n        self.model = create_network(model, device=device)\n    else:\n        raise ValueError(f\"Invalid model {type(model)}\")\n    if verbose:\n        get_num_parameters(self.model, verbose=True)\n\n    self.data_sb = data_scaling_bias\n\n    self.reg_val = reg_tv_val\n    self.device = device\n    self.save_epochs_dir = save_epochs_dir\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/autoden/#autoden.N2N.infer","title":"infer","text":"<pre><code>infer(inp: NDArray) -&gt; NDArray\n</code></pre> <p>Inference, given an initial stack of images.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input stack of images</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>The denoised stack of images</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def infer(self, inp: NDArray) -&gt; NDArray:\n    \"\"\"Inference, given an initial stack of images.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input stack of images\n\n    Returns\n    -------\n    NDArray\n        The denoised stack of images\n    \"\"\"\n    # Rescale input\n    if self.data_sb is not None:\n        inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n\n    inp_t = _single_channel_imgs_to_tensor(inp, device=self.device)\n\n    self.model.eval()\n    with pt.inference_mode():\n        out_t: pt.Tensor = self.model(inp_t)\n        output = out_t.to(\"cpu\").numpy().reshape(inp.shape)\n\n    # Rescale output\n    if self.data_sb is not None:\n        output = (output + self.data_sb.bias_out) / self.data_sb.scaling_out\n\n    return output\n</code></pre>"},{"location":"reference/autoden/#autoden.N2N.train_supervised","title":"train_supervised","text":"<pre><code>train_supervised(inp: NDArray, tgt: NDArray, epochs: int, tst_inds: Sequence[int] | NDArray, algo: str = 'adam')\n</code></pre> <p>Supervised training.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input images</p> </li> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>The target images</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>Number of training epochs</p> </li> <li> <code>tst_inds</code>               (<code>Sequence[int] | NDArray</code>)           \u2013            <p>The validation set indices</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>Learning algorithm to use, by default \"adam\"</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_supervised(\n    self,\n    inp: NDArray,\n    tgt: NDArray,\n    epochs: int,\n    tst_inds: Sequence[int] | NDArray,\n    algo: str = \"adam\",\n):\n    \"\"\"Supervised training.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input images\n    tgt : NDArray\n        The target images\n    epochs : int\n        Number of training epochs\n    tst_inds : Sequence[int] | NDArray\n        The validation set indices\n    algo : str, optional\n        Learning algorithm to use, by default \"adam\"\n    \"\"\"\n    num_imgs = inp.shape[0]\n    tst_inds = np.array(tst_inds, dtype=int)\n    if np.any(tst_inds &lt; 0) or np.any(tst_inds &gt;= num_imgs):\n        raise ValueError(\n            f\"Each cross-validation index should be greater or equal than 0, and less than the number of images {num_imgs}\"\n        )\n    trn_inds = np.delete(np.arange(num_imgs), obj=tst_inds)\n\n    if tgt.ndim == (inp.ndim - 1):\n        tgt = np.tile(tgt[None, ...], [num_imgs, *np.ones_like(tgt.shape)])\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_supervised(inp, tgt)\n\n    # Rescale the datasets\n    inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n    tgt = tgt * self.data_sb.scaling_tgt - self.data_sb.bias_tgt\n\n    # Create datasets\n    dset_trn = (inp[trn_inds], tgt[trn_inds])\n    dset_tst = (inp[tst_inds], tgt[tst_inds])\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    loss_trn, loss_tst = self._train_selfsimilar(dset_trn, dset_tst, epochs=epochs, algo=algo, regularizer=reg)\n\n    if self.verbose:\n        self._plot_loss_curves(loss_trn, loss_tst, f\"Supervised {algo.upper()}\")\n</code></pre>"},{"location":"reference/autoden/#autoden.N2V","title":"N2V","text":"<pre><code>N2V(model: int | str | NetworkParams | Module | Mapping, data_scaling_bias: DataScalingBias | None = None, reg_tv_val: float | None = 1e-05, device: str = 'cuda' if is_available() else 'cpu', save_epochs_dir: str | None = None, verbose: bool = True)\n</code></pre> <p>               Bases: <code>Denoiser</code></p> <p>Self-supervised denoising from single images.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str | NetworkParams | Module | Mapping | None</code>)           \u2013            <p>Type of neural network to use or a specific network (or state) to use</p> </li> <li> <code>data_scaling_bias</code>               (<code>DataScalingBias | None</code>, default:                   <code>None</code> )           \u2013            <p>Scaling and bias of the input data, by default None</p> </li> <li> <code>reg_tv_val</code>               (<code>float | None</code>, default:                   <code>1e-05</code> )           \u2013            <p>Deep-image prior regularization value, by default 1e-5</p> </li> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"</p> </li> <li> <code>save_epochs_dir</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Directory where to save network states at each epoch. If None disabled, by default None</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to produce verbose output, by default True</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>infer</code>             \u2013              <p>Inference, given an initial stack of images.</p> </li> <li> <code>train_selfsupervised</code>             \u2013              <p>Self-supervised training.</p> </li> <li> <code>train_supervised</code>             \u2013              <p>Supervised training.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def __init__(\n    self,\n    model: int | str | NetworkParams | pt.nn.Module | Mapping,\n    data_scaling_bias: DataScalingBias | None = None,\n    reg_tv_val: float | None = 1e-5,\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n    save_epochs_dir: str | None = None,\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"Initialize the noise2noise method.\n\n    Parameters\n    ----------\n    model : str | NetworkParams | pt.nn.Module | Mapping | None\n        Type of neural network to use or a specific network (or state) to use\n    data_scaling_bias : DataScalingBias | None, optional\n        Scaling and bias of the input data, by default None\n    reg_tv_val : float | None, optional\n        Deep-image prior regularization value, by default 1e-5\n    device : str, optional\n        Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"\n    save_epochs_dir : str | None, optional\n        Directory where to save network states at each epoch.\n        If None disabled, by default None\n    verbose : bool, optional\n        Whether to produce verbose output, by default True\n    \"\"\"\n    if isinstance(model, int):\n        if self.save_epochs_dir is None:\n            raise ValueError(\"Directory for saving epochs not specified\")\n\n        model = load_model_state(self.save_epochs_dir, epoch_num=model)\n\n    if isinstance(model, (str, NetworkParams, Mapping, pt.nn.Module)):\n        self.model = create_network(model, device=device)\n    else:\n        raise ValueError(f\"Invalid model {type(model)}\")\n    if verbose:\n        get_num_parameters(self.model, verbose=True)\n\n    self.data_sb = data_scaling_bias\n\n    self.reg_val = reg_tv_val\n    self.device = device\n    self.save_epochs_dir = save_epochs_dir\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/autoden/#autoden.N2V.infer","title":"infer","text":"<pre><code>infer(inp: NDArray) -&gt; NDArray\n</code></pre> <p>Inference, given an initial stack of images.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input stack of images</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>The denoised stack of images</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def infer(self, inp: NDArray) -&gt; NDArray:\n    \"\"\"Inference, given an initial stack of images.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input stack of images\n\n    Returns\n    -------\n    NDArray\n        The denoised stack of images\n    \"\"\"\n    # Rescale input\n    if self.data_sb is not None:\n        inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n\n    inp_t = _single_channel_imgs_to_tensor(inp, device=self.device)\n\n    self.model.eval()\n    with pt.inference_mode():\n        out_t: pt.Tensor = self.model(inp_t)\n        output = out_t.to(\"cpu\").numpy().reshape(inp.shape)\n\n    # Rescale output\n    if self.data_sb is not None:\n        output = (output + self.data_sb.bias_out) / self.data_sb.scaling_out\n\n    return output\n</code></pre>"},{"location":"reference/autoden/#autoden.N2V.train_selfsupervised","title":"train_selfsupervised","text":"<pre><code>train_selfsupervised(inp: NDArray, epochs: int, tst_inds: Sequence[int] | NDArray, mask_shape: int | Sequence[int] | NDArray = 1, ratio_blind_spot: float = 0.015, algo: str = 'adam')\n</code></pre> <p>Self-supervised training.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input images, which will also be targets</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>Number of training epochs</p> </li> <li> <code>tst_inds</code>               (<code>Sequence[int] | NDArray</code>)           \u2013            <p>The validation set indices</p> </li> <li> <code>mask_shape</code>               (<code>int | Sequence[int] | NDArray</code>, default:                   <code>1</code> )           \u2013            <p>Shape of the blind spot mask, by default 1.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>Learning algorithm to use, by default \"adam\"</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_selfsupervised(\n    self,\n    inp: NDArray,\n    epochs: int,\n    tst_inds: Sequence[int] | NDArray,\n    mask_shape: int | Sequence[int] | NDArray = 1,\n    ratio_blind_spot: float = 0.015,\n    algo: str = \"adam\",\n):\n    \"\"\"Self-supervised training.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input images, which will also be targets\n    epochs : int\n        Number of training epochs\n    tst_inds : Sequence[int] | NDArray\n        The validation set indices\n    mask_shape : int | Sequence[int] | NDArray\n        Shape of the blind spot mask, by default 1.\n    algo : str, optional\n        Learning algorithm to use, by default \"adam\"\n    \"\"\"\n    num_imgs = inp.shape[0]\n    tst_inds = np.array(tst_inds, dtype=int)\n    if np.any(tst_inds &lt; 0) or np.any(tst_inds &gt;= num_imgs):\n        raise ValueError(\n            f\"Each cross-validation index should be greater or equal than 0, and less than the number of images {num_imgs}\"\n        )\n    trn_inds = np.delete(np.arange(num_imgs), obj=tst_inds)\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_selfsupervised(inp)\n\n    # Rescale the datasets\n    inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n\n    inp_trn = inp[trn_inds]\n    inp_tst = inp[tst_inds]\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    losses_trn, losses_tst = self._train_n2v_pixelmask_small(\n        inp_trn,\n        inp_tst,\n        epochs=epochs,\n        mask_shape=mask_shape,\n        ratio_blind_spot=ratio_blind_spot,\n        algo=algo,\n        regularizer=reg,\n    )\n\n    self._plot_loss_curves(losses_trn, losses_tst, f\"Self-supervised {self.__class__.__name__} {algo.upper()}\")\n</code></pre>"},{"location":"reference/autoden/#autoden.N2V.train_supervised","title":"train_supervised","text":"<pre><code>train_supervised(inp: NDArray, tgt: NDArray, epochs: int, tst_inds: Sequence[int] | NDArray, algo: str = 'adam')\n</code></pre> <p>Supervised training.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input images</p> </li> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>The target images</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>Number of training epochs</p> </li> <li> <code>tst_inds</code>               (<code>Sequence[int] | NDArray</code>)           \u2013            <p>The validation set indices</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>Learning algorithm to use, by default \"adam\"</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_supervised(\n    self,\n    inp: NDArray,\n    tgt: NDArray,\n    epochs: int,\n    tst_inds: Sequence[int] | NDArray,\n    algo: str = \"adam\",\n):\n    \"\"\"Supervised training.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input images\n    tgt : NDArray\n        The target images\n    epochs : int\n        Number of training epochs\n    tst_inds : Sequence[int] | NDArray\n        The validation set indices\n    algo : str, optional\n        Learning algorithm to use, by default \"adam\"\n    \"\"\"\n    num_imgs = inp.shape[0]\n    tst_inds = np.array(tst_inds, dtype=int)\n    if np.any(tst_inds &lt; 0) or np.any(tst_inds &gt;= num_imgs):\n        raise ValueError(\n            f\"Each cross-validation index should be greater or equal than 0, and less than the number of images {num_imgs}\"\n        )\n    trn_inds = np.delete(np.arange(num_imgs), obj=tst_inds)\n\n    if tgt.ndim == (inp.ndim - 1):\n        tgt = np.tile(tgt[None, ...], [num_imgs, *np.ones_like(tgt.shape)])\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_supervised(inp, tgt)\n\n    # Rescale the datasets\n    inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n    tgt = tgt * self.data_sb.scaling_tgt - self.data_sb.bias_tgt\n\n    # Create datasets\n    dset_trn = (inp[trn_inds], tgt[trn_inds])\n    dset_tst = (inp[tst_inds], tgt[tst_inds])\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    loss_trn, loss_tst = self._train_selfsimilar(dset_trn, dset_tst, epochs=epochs, algo=algo, regularizer=reg)\n\n    if self.verbose:\n        self._plot_loss_curves(loss_trn, loss_tst, f\"Supervised {algo.upper()}\")\n</code></pre>"},{"location":"reference/autoden/#autoden.NetworkParams","title":"NetworkParams","text":"<pre><code>NetworkParams(n_features: int, n_channels_in: int = 1, n_channels_out: int = 1)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for storing network parameters.</p> <p>Methods:</p> <ul> <li> <code>get_model</code>             \u2013              <p>Get the associated model with the selected parameters.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>def __init__(self, n_features: int, n_channels_in: int = 1, n_channels_out: int = 1) -&gt; None:\n    self.n_channels_in = n_channels_in\n    self.n_channels_out = n_channels_out\n    self.n_features = n_features\n</code></pre>"},{"location":"reference/autoden/#autoden.NetworkParams.get_model","title":"get_model  <code>abstractmethod</code>","text":"<pre><code>get_model(device: str = 'cuda' if is_available() else 'cpu') -&gt; Module\n</code></pre> <p>Get the associated model with the selected parameters.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>The device that the the model should run on, by default \"cuda\" if cuda is available, otherwise \"cpu\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Module</code>           \u2013            <p>The model.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>@abstractmethod\ndef get_model(self, device: str = \"cuda\" if is_cuda_available() else \"cpu\") -&gt; Module:\n    \"\"\"Get the associated model with the selected parameters.\n\n    Parameters\n    ----------\n    device : str, optional\n        The device that the the model should run on, by default \"cuda\" if cuda is available, otherwise \"cpu\".\n\n    Returns\n    -------\n    Module\n        The model.\n    \"\"\"\n</code></pre>"},{"location":"reference/autoden/#autoden.compute_scaling_selfsupervised","title":"compute_scaling_selfsupervised","text":"<pre><code>compute_scaling_selfsupervised(inp: NDArray) -&gt; DataScalingBias\n</code></pre> <p>Compute input data scaling and bias for self-supervised learning.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>Input data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataScalingBias</code>           \u2013            <p>An instance of DataScalingBias containing the computed scaling and bias values.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def compute_scaling_selfsupervised(inp: NDArray) -&gt; DataScalingBias:\n    \"\"\"\n    Compute input data scaling and bias for self-supervised learning.\n\n    Parameters\n    ----------\n    inp : NDArray\n        Input data.\n\n    Returns\n    -------\n    DataScalingBias\n        An instance of DataScalingBias containing the computed scaling and bias values.\n    \"\"\"\n    range_vals_inp = _get_normalization(inp, percentile=0.001)\n\n    sb = DataScalingBias()\n    sb.scaling_inp = 1 / (range_vals_inp[1] - range_vals_inp[0])\n    sb.scaling_out = sb.scaling_tgt = sb.scaling_inp\n\n    sb.bias_inp = range_vals_inp[2] * sb.scaling_inp\n    sb.bias_out = sb.bias_tgt = sb.bias_inp\n\n    return sb\n</code></pre>"},{"location":"reference/autoden/#autoden.compute_scaling_supervised","title":"compute_scaling_supervised","text":"<pre><code>compute_scaling_supervised(inp: NDArray, tgt: NDArray) -&gt; DataScalingBias\n</code></pre> <p>Compute input and target data scaling and bias for supervised learning.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>Input data.</p> </li> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>Target data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataScalingBias</code>           \u2013            <p>An instance of DataScalingBias containing the computed scaling and bias values.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def compute_scaling_supervised(inp: NDArray, tgt: NDArray) -&gt; DataScalingBias:\n    \"\"\"\n    Compute input and target data scaling and bias for supervised learning.\n\n    Parameters\n    ----------\n    inp : NDArray\n        Input data.\n    tgt : NDArray\n        Target data.\n\n    Returns\n    -------\n    DataScalingBias\n        An instance of DataScalingBias containing the computed scaling and bias values.\n    \"\"\"\n    range_vals_inp = _get_normalization(inp, percentile=0.001)\n    range_vals_tgt = _get_normalization(tgt, percentile=0.001)\n\n    sb = DataScalingBias()\n    sb.scaling_inp = 1 / (range_vals_inp[1] - range_vals_inp[0])\n    sb.scaling_tgt = 1 / (range_vals_tgt[1] - range_vals_tgt[0])\n    sb.scaling_out = sb.scaling_tgt\n\n    sb.bias_inp = range_vals_inp[2] * sb.scaling_inp\n    sb.bias_tgt = range_vals_tgt[2] * sb.scaling_tgt\n    sb.bias_out = sb.bias_tgt\n\n    return sb\n</code></pre>"},{"location":"reference/autoden/#autoden.create_network","title":"create_network","text":"<pre><code>create_network(model: str | NetworkParams | Mapping | Module, state_dict: Mapping | None = None, device: str = 'cuda' if is_available() else 'cpu') -&gt; Module\n</code></pre> <p>Create and return a neural network model based on the provided network configuration.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str | NetworkParams | Mapping | Module</code>)           \u2013            <p>The network configuration. It can be a string specifying the network type, an instance of <code>NetworkParams</code>, or an already instantiated <code>Module</code>. If a string is provided, it must be one of the supported network types: \"msd\", \"unet\", or \"dncnn\".</p> </li> <li> <code>state_dict</code>               (<code>Mapping | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary containing the state dictionary of the model. If provided, the model's parameters will be loaded from this dictionary. Default is None.</p> </li> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>The device to which the model should be moved. Default is \"cuda\" if CUDA is available, otherwise \"cpu\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Module</code>           \u2013            <p>The created neural network model.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the provided network name is invalid or the network type is not supported.</p> </li> </ul> Notes <p>The function supports the following network types: - \"msd\": Multi-Scale Dense Network. - \"unet\": U-Net. - \"dncnn\": Denoising Convolutional Neural Network.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; net = create_network(\"unet\")\n&gt;&gt;&gt; print(net)\nModel UNet - num. parameters: 1234567\n</code></pre> Source code in <code>src/autoden/models/config.py</code> <pre><code>def create_network(\n    model: str | NetworkParams | Mapping | Module,\n    state_dict: Mapping | None = None,\n    device: str = \"cuda\" if is_cuda_available() else \"cpu\",\n) -&gt; Module:\n    \"\"\"\n    Create and return a neural network model based on the provided network configuration.\n\n    Parameters\n    ----------\n    model : str | NetworkParams | Mapping | Module\n        The network configuration. It can be a string specifying the network type,\n        an instance of `NetworkParams`, or an already instantiated `Module`.\n        If a string is provided, it must be one of the supported network types:\n        \"msd\", \"unet\", or \"dncnn\".\n    state_dict : Mapping | None, optional\n        A dictionary containing the state dictionary of the model. If provided,\n        the model's parameters will be loaded from this dictionary. Default is None.\n    device : str, optional\n        The device to which the model should be moved. Default is \"cuda\" if CUDA is available,\n        otherwise \"cpu\".\n\n    Returns\n    -------\n    Module\n        The created neural network model.\n\n    Raises\n    ------\n    ValueError\n        If the provided network name is invalid or the network type is not supported.\n\n    Notes\n    -----\n    The function supports the following network types:\n    - \"msd\": Multi-Scale Dense Network.\n    - \"unet\": U-Net.\n    - \"dncnn\": Denoising Convolutional Neural Network.\n\n    Examples\n    --------\n    &gt;&gt;&gt; net = create_network(\"unet\")\n    &gt;&gt;&gt; print(net)\n    Model UNet - num. parameters: 1234567\n    \"\"\"\n    if isinstance(model, Mapping):\n        if (\"model_class\", \"state_dict\") not in model:\n            raise ValueError(\"Malformed model state dictionary. Expected two mandatory fields: 'model_class' and 'state_dict'\")\n        state_dict = model[\"state_dict\"]\n        model = model[\"model_class\"]\n\n    if isinstance(model, str):\n        if model.lower() in (\"msd\", MSDnet.__name__.lower()):\n            model = NetworkParamsMSD()\n        elif model.lower() == UNet.__name__.lower():\n            model = NetworkParamsUNet()\n        elif model.lower() == DnCNN.__name__.lower():\n            model = NetworkParamsDnCNN()\n        else:\n            raise ValueError(f\"Invalid model name: {model}\")\n\n    if isinstance(model, NetworkParams):\n        net = model.get_model(device)\n    elif isinstance(model, Module):\n        net = model.to(device=device)\n    else:\n        raise ValueError(f\"Invalid model type: {type(model)}\")\n\n    if state_dict is not None:\n        net.load_state_dict(state_dict)\n        net.to(device)  # Needed to ensure that the model lives in the correct device\n\n    print(f\"Model {net.__class__.__name__} - num. parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad)}\")\n    return net\n</code></pre>"},{"location":"reference/autoden/#autoden.create_optimizer","title":"create_optimizer","text":"<pre><code>create_optimizer(network: Module, algo: str = 'adam', learning_rate: float = 0.001, weight_decay: float = 0.01, optim_state: Mapping | None = None) -&gt; Optimizer\n</code></pre> <p>Instantiates the desired optimizer for the given model.</p> <p>Parameters:</p> <ul> <li> <code>network</code>               (<code>Module</code>)           \u2013            <p>The network to train.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>The requested optimizer, by default \"adam\".</p> </li> <li> <code>learning_rate</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The desired learning rate, by default 1e-3.</p> </li> <li> <code>weight_decay</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>The desired weight decay, by default 1e-2.</p> </li> <li> <code>optim_state</code>               (<code>Mapping | None</code>, default:                   <code>None</code> )           \u2013            <p>The state dictionary for the optimizer, by default None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Optimizer</code>           \u2013            <p>The chosen optimizer.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unsupported algorithm is requested.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>def create_optimizer(\n    network: Module,\n    algo: str = \"adam\",\n    learning_rate: float = 1e-3,\n    weight_decay: float = 1e-2,\n    optim_state: Mapping | None = None,\n) -&gt; pt.optim.Optimizer:\n    \"\"\"Instantiates the desired optimizer for the given model.\n\n    Parameters\n    ----------\n    network : torch.nn.Module\n        The network to train.\n    algo : str, optional\n        The requested optimizer, by default \"adam\".\n    learning_rate : float, optional\n        The desired learning rate, by default 1e-3.\n    weight_decay : float, optional\n        The desired weight decay, by default 1e-2.\n    optim_state : Mapping | None, optional\n        The state dictionary for the optimizer, by default None.\n\n    Returns\n    -------\n    torch.optim.Optimizer\n        The chosen optimizer.\n\n    Raises\n    ------\n    ValueError\n        If an unsupported algorithm is requested.\n    \"\"\"\n    if algo.lower() == \"adam\":\n        optimizer = pt.optim.AdamW(network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    elif algo.lower() == \"sgd\":\n        optimizer = pt.optim.SGD(network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    elif algo.lower() == \"rmsprop\":\n        optimizer = pt.optim.RMSprop(network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    elif algo.lower() == \"lbfgs\":\n        optimizer = pt.optim.LBFGS(network.parameters(), lr=learning_rate, max_iter=10000, history_size=50)\n    else:\n        raise ValueError(f\"Unknown algorithm: {algo}\")\n\n    if optim_state is not None:\n        optimizer.load_state_dict(dict(**optim_state))\n\n    return optimizer\n</code></pre>"},{"location":"reference/autoden/#autoden.fix_invalid_gradient_values","title":"fix_invalid_gradient_values","text":"<pre><code>fix_invalid_gradient_values(model: Module) -&gt; None\n</code></pre> <p>Fixes invalid gradient values in the model's parameters.</p> <p>This function iterates over all parameters of the given model and sets the gradient values to zero where they are not finite (i.e., NaN or infinity).</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The neural network model whose gradient values need to be fixed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>This function modifies the gradients in place and does not return anything.</p> </li> </ul> Source code in <code>src/autoden/models/param_utils.py</code> <pre><code>def fix_invalid_gradient_values(model: nn.Module) -&gt; None:\n    \"\"\"\n    Fixes invalid gradient values in the model's parameters.\n\n    This function iterates over all parameters of the given model and sets the\n    gradient values to zero where they are not finite (i.e., NaN or infinity).\n\n    Parameters\n    ----------\n    model : nn.Module\n        The neural network model whose gradient values need to be fixed.\n\n    Returns\n    -------\n    None\n        This function modifies the gradients in place and does not return anything.\n    \"\"\"\n    for pars in model.parameters():\n        if pars.grad is not None:\n            pars.grad[pt.logical_not(pt.isfinite(pars.grad))] = 0.0\n</code></pre>"},{"location":"reference/autoden/#autoden.get_num_parameters","title":"get_num_parameters","text":"<pre><code>get_num_parameters(model: Module, verbose: bool = False) -&gt; int\n</code></pre> <p>Returns the number of trainable parameters in the model.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The model to count the parameters for.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, prints the number of parameters, by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>The number of trainable parameters.</p> </li> </ul> Source code in <code>src/autoden/models/param_utils.py</code> <pre><code>def get_num_parameters(model: nn.Module, verbose: bool = False) -&gt; int:\n    \"\"\"Returns the number of trainable parameters in the model.\n\n    Parameters\n    ----------\n    model : torch.nn.Module\n        The model to count the parameters for.\n    verbose : bool, optional\n        If True, prints the number of parameters, by default False.\n\n    Returns\n    -------\n    int\n        The number of trainable parameters.\n    \"\"\"\n    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    if verbose:\n        print(f\"Model {model.__class__.__name__} - num. parameters: {num_params}\")\n    return num_params\n</code></pre>"},{"location":"reference/autoden/#autoden.load_model_state","title":"load_model_state","text":"<pre><code>load_model_state(save_epochs_dir: str | Path, epoch_num: int | None = None) -&gt; Mapping\n</code></pre> <p>Load a model from disk.</p> <p>Parameters:</p> <ul> <li> <code>save_epochs_dir</code>               (<code>str | Path</code>)           \u2013            <p>The director where the models are saved</p> </li> <li> <code>epoch_num</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The epoch number or if None/-1 the best state will be loaded, by default None</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Mapping</code>           \u2013            <p>The loaded model state and possibly an optimizer state.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When the directory does not exist or the requested model is not available.</p> </li> </ul> Source code in <code>src/autoden/io.py</code> <pre><code>def load_model_state(save_epochs_dir: str | Path, epoch_num: int | None = None) -&gt; Mapping:\n    \"\"\"Load a model from disk.\n\n    Parameters\n    ----------\n    save_epochs_dir : str | Path\n        The director where the models are saved\n    epoch_num : int | None, optional\n        The epoch number or if None/-1 the best state will be loaded, by default None\n\n    Returns\n    -------\n    Mapping\n        The loaded model state and possibly an optimizer state.\n\n    Raises\n    ------\n    ValueError\n        When the directory does not exist or the requested model is not available.\n    \"\"\"\n    epochs_base_path = Path(save_epochs_dir) / \"weights\"\n    if not epochs_base_path.exists():\n        raise ValueError(f\"Directory of the model state {epochs_base_path} does not exist!\")\n\n    if epoch_num is None or epoch_num == -1:\n        state_path = epochs_base_path / \"weights.pt\"\n    else:\n        state_path = epochs_base_path / f\"weights_epoch_{epoch_num}.pt\"\n    if not state_path.exists():\n        raise ValueError(f\"Model state {state_path} does not exist!\")\n\n    print(f\"Loading state path: {state_path}\")\n    return pt.load(state_path)\n</code></pre>"},{"location":"reference/autoden/#autoden.save_model_state","title":"save_model_state","text":"<pre><code>save_model_state(save_epochs_dir: str | Path, epoch_num: int, model: Module, optim_state: Mapping | None = None, is_best: bool = False) -&gt; None\n</code></pre> <p>Save a model's state to disk.</p> <p>This function saves the state of a model and optionally its optimizer to disk. The model state is saved in a directory specified by <code>save_epochs_dir</code>. If <code>is_best</code> is True, the model state is saved as \"weights.pt\". Otherwise, it is saved with a filename that includes the epoch number.</p> <p>Parameters:</p> <ul> <li> <code>save_epochs_dir</code>               (<code>str | Path</code>)           \u2013            <p>The directory where to save the model state.</p> </li> <li> <code>epoch_num</code>               (<code>int</code>)           \u2013            <p>The epoch number.</p> </li> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The model whose state is to be saved.</p> </li> <li> <code>optim_state</code>               (<code>Mapping</code>, default:                   <code>None</code> )           \u2013            <p>The optimizer state to save, by default None.</p> </li> <li> <code>is_best</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether it is the best fitted model, by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            </li> </ul> Source code in <code>src/autoden/io.py</code> <pre><code>def save_model_state(\n    save_epochs_dir: str | Path,\n    epoch_num: int,\n    model: Module,\n    optim_state: Mapping | None = None,\n    is_best: bool = False,\n) -&gt; None:\n    \"\"\"Save a model's state to disk.\n\n    This function saves the state of a model and optionally its optimizer to disk.\n    The model state is saved in a directory specified by `save_epochs_dir`. If\n    `is_best` is True, the model state is saved as \"weights.pt\". Otherwise, it is\n    saved with a filename that includes the epoch number.\n\n    Parameters\n    ----------\n    save_epochs_dir : str | Path\n        The directory where to save the model state.\n    epoch_num : int\n        The epoch number.\n    model : Module\n        The model whose state is to be saved.\n    optim_state : Mapping, optional\n        The optimizer state to save, by default None.\n    is_best : bool, optional\n        Whether it is the best fitted model, by default False.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    epochs_base_path = Path(save_epochs_dir) / \"weights\"\n    epochs_base_path.mkdir(parents=True, exist_ok=True)\n\n    pt.save(\n        {\"model\": model.__class__.__name__, \"epoch\": epoch_num, \"state_dict\": model.state_dict(), \"optimizer\": optim_state},\n        epochs_base_path / (\"weights.pt\" if is_best else f\"weights_epoch_{epoch_num}.pt\"),\n    )\n</code></pre>"},{"location":"reference/autoden/algorithms/","title":"autoden.algorithms","text":""},{"location":"reference/autoden/algorithms/#autoden.algorithms","title":"algorithms","text":"<p>Implementation of various unsupervised and self-supervised denoising methods.</p> <p>Classes:</p> <ul> <li> <code>DIP</code>           \u2013            <p>Deep image prior.</p> </li> <li> <code>DataScalingBias</code>           \u2013            <p>Data scaling and bias.</p> </li> <li> <code>Denoiser</code>           \u2013            <p>Denoising images.</p> </li> <li> <code>N2N</code>           \u2013            <p>Self-supervised denoising from pairs of images.</p> </li> <li> <code>N2V</code>           \u2013            <p>Self-supervised denoising from single images.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>compute_scaling_selfsupervised</code>             \u2013              <p>Compute input data scaling and bias for self-supervised learning.</p> </li> <li> <code>compute_scaling_supervised</code>             \u2013              <p>Compute input and target data scaling and bias for supervised learning.</p> </li> </ul>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.DIP","title":"DIP","text":"<pre><code>DIP(model: int | str | NetworkParams | Module | Mapping, data_scaling_bias: DataScalingBias | None = None, reg_tv_val: float | None = 1e-05, device: str = 'cuda' if is_available() else 'cpu', save_epochs_dir: str | None = None, verbose: bool = True)\n</code></pre> <p>               Bases: <code>Denoiser</code></p> <p>Deep image prior.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str | NetworkParams | Module | Mapping | None</code>)           \u2013            <p>Type of neural network to use or a specific network (or state) to use</p> </li> <li> <code>data_scaling_bias</code>               (<code>DataScalingBias | None</code>, default:                   <code>None</code> )           \u2013            <p>Scaling and bias of the input data, by default None</p> </li> <li> <code>reg_tv_val</code>               (<code>float | None</code>, default:                   <code>1e-05</code> )           \u2013            <p>Deep-image prior regularization value, by default 1e-5</p> </li> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"</p> </li> <li> <code>save_epochs_dir</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Directory where to save network states at each epoch. If None disabled, by default None</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to produce verbose output, by default True</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>infer</code>             \u2013              <p>Inference, given an initial stack of images.</p> </li> <li> <code>train_supervised</code>             \u2013              <p>Supervised training.</p> </li> <li> <code>train_unsupervised</code>             \u2013              <p>Train the model in an unsupervised manner.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def __init__(\n    self,\n    model: int | str | NetworkParams | pt.nn.Module | Mapping,\n    data_scaling_bias: DataScalingBias | None = None,\n    reg_tv_val: float | None = 1e-5,\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n    save_epochs_dir: str | None = None,\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"Initialize the noise2noise method.\n\n    Parameters\n    ----------\n    model : str | NetworkParams | pt.nn.Module | Mapping | None\n        Type of neural network to use or a specific network (or state) to use\n    data_scaling_bias : DataScalingBias | None, optional\n        Scaling and bias of the input data, by default None\n    reg_tv_val : float | None, optional\n        Deep-image prior regularization value, by default 1e-5\n    device : str, optional\n        Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"\n    save_epochs_dir : str | None, optional\n        Directory where to save network states at each epoch.\n        If None disabled, by default None\n    verbose : bool, optional\n        Whether to produce verbose output, by default True\n    \"\"\"\n    if isinstance(model, int):\n        if self.save_epochs_dir is None:\n            raise ValueError(\"Directory for saving epochs not specified\")\n\n        model = load_model_state(self.save_epochs_dir, epoch_num=model)\n\n    if isinstance(model, (str, NetworkParams, Mapping, pt.nn.Module)):\n        self.model = create_network(model, device=device)\n    else:\n        raise ValueError(f\"Invalid model {type(model)}\")\n    if verbose:\n        get_num_parameters(self.model, verbose=True)\n\n    self.data_sb = data_scaling_bias\n\n    self.reg_val = reg_tv_val\n    self.device = device\n    self.save_epochs_dir = save_epochs_dir\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.DIP.infer","title":"infer","text":"<pre><code>infer(inp: NDArray) -&gt; NDArray\n</code></pre> <p>Inference, given an initial stack of images.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input stack of images</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>The denoised stack of images</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def infer(self, inp: NDArray) -&gt; NDArray:\n    \"\"\"Inference, given an initial stack of images.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input stack of images\n\n    Returns\n    -------\n    NDArray\n        The denoised stack of images\n    \"\"\"\n    # Rescale input\n    if self.data_sb is not None:\n        inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n\n    inp_t = _single_channel_imgs_to_tensor(inp, device=self.device)\n\n    self.model.eval()\n    with pt.inference_mode():\n        out_t: pt.Tensor = self.model(inp_t)\n        output = out_t.to(\"cpu\").numpy().reshape(inp.shape)\n\n    # Rescale output\n    if self.data_sb is not None:\n        output = (output + self.data_sb.bias_out) / self.data_sb.scaling_out\n\n    return output\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.DIP.train_supervised","title":"train_supervised","text":"<pre><code>train_supervised(inp: NDArray, tgt: NDArray, epochs: int, tst_inds: Sequence[int] | NDArray, algo: str = 'adam')\n</code></pre> <p>Supervised training.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input images</p> </li> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>The target images</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>Number of training epochs</p> </li> <li> <code>tst_inds</code>               (<code>Sequence[int] | NDArray</code>)           \u2013            <p>The validation set indices</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>Learning algorithm to use, by default \"adam\"</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_supervised(\n    self,\n    inp: NDArray,\n    tgt: NDArray,\n    epochs: int,\n    tst_inds: Sequence[int] | NDArray,\n    algo: str = \"adam\",\n):\n    \"\"\"Supervised training.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input images\n    tgt : NDArray\n        The target images\n    epochs : int\n        Number of training epochs\n    tst_inds : Sequence[int] | NDArray\n        The validation set indices\n    algo : str, optional\n        Learning algorithm to use, by default \"adam\"\n    \"\"\"\n    num_imgs = inp.shape[0]\n    tst_inds = np.array(tst_inds, dtype=int)\n    if np.any(tst_inds &lt; 0) or np.any(tst_inds &gt;= num_imgs):\n        raise ValueError(\n            f\"Each cross-validation index should be greater or equal than 0, and less than the number of images {num_imgs}\"\n        )\n    trn_inds = np.delete(np.arange(num_imgs), obj=tst_inds)\n\n    if tgt.ndim == (inp.ndim - 1):\n        tgt = np.tile(tgt[None, ...], [num_imgs, *np.ones_like(tgt.shape)])\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_supervised(inp, tgt)\n\n    # Rescale the datasets\n    inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n    tgt = tgt * self.data_sb.scaling_tgt - self.data_sb.bias_tgt\n\n    # Create datasets\n    dset_trn = (inp[trn_inds], tgt[trn_inds])\n    dset_tst = (inp[tst_inds], tgt[tst_inds])\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    loss_trn, loss_tst = self._train_selfsimilar(dset_trn, dset_tst, epochs=epochs, algo=algo, regularizer=reg)\n\n    if self.verbose:\n        self._plot_loss_curves(loss_trn, loss_tst, f\"Supervised {algo.upper()}\")\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.DIP.train_unsupervised","title":"train_unsupervised","text":"<pre><code>train_unsupervised(tgt: NDArray, epochs: int, inp: NDArray | None = None, num_tst_ratio: float = 0.2, algo: str = 'adam') -&gt; NDArray\n</code></pre> <p>Train the model in an unsupervised manner.</p> <p>Parameters:</p> <ul> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>The target image to be denoised.</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>The number of training epochs.</p> </li> <li> <code>inp</code>               (<code>NDArray | None</code>, default:                   <code>None</code> )           \u2013            <p>The input image. If None, a random image will be generated. Default is None.</p> </li> <li> <code>num_tst_ratio</code>               (<code>float</code>, default:                   <code>0.2</code> )           \u2013            <p>The ratio of the test set size to the total dataset size. Default is 0.2.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>The optimization algorithm to use. Default is \"adam\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>The denoised input image.</p> </li> </ul> Notes <p>This method trains the model using the deep image prior approach in an unsupervised manner. It uses a random initialization for the input image if not provided and applies a scaling and bias transformation to the input and target images. It then splits the data into training and test sets based on the provided ratio and trains the model using the specified optimization algorithm.</p> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_unsupervised(\n    self, tgt: NDArray, epochs: int, inp: NDArray | None = None, num_tst_ratio: float = 0.2, algo: str = \"adam\"\n) -&gt; NDArray:\n    \"\"\"\n    Train the model in an unsupervised manner.\n\n    Parameters\n    ----------\n    tgt : NDArray\n        The target image to be denoised.\n    epochs : int\n        The number of training epochs.\n    inp : NDArray | None, optional\n        The input image. If None, a random image will be generated.\n        Default is None.\n    num_tst_ratio : float, optional\n        The ratio of the test set size to the total dataset size.\n        Default is 0.2.\n    algo : str, optional\n        The optimization algorithm to use. Default is \"adam\".\n\n    Returns\n    -------\n    NDArray\n        The denoised input image.\n\n    Notes\n    -----\n    This method trains the model using the deep image prior approach in an unsupervised manner.\n    It uses a random initialization for the input image if not provided and applies a scaling and bias\n    transformation to the input and target images. It then splits the data into training and test sets\n    based on the provided ratio and trains the model using the specified optimization algorithm.\n    \"\"\"\n    if inp is None:\n        inp = np.random.normal(size=tgt.shape[-2:], scale=0.25).astype(tgt.dtype)\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_supervised(inp, tgt)\n\n    # Rescale the datasets\n    tmp_inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n    tmp_tgt = tgt * self.data_sb.scaling_tgt - self.data_sb.bias_tgt\n\n    mask_trn = np.ones_like(tgt, dtype=bool)\n    rnd_inds = np.random.random_integers(low=0, high=mask_trn.size - 1, size=int(mask_trn.size * num_tst_ratio))\n    mask_trn[np.unravel_index(rnd_inds, shape=mask_trn.shape)] = False\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    losses_trn, losses_tst = self._train_pixelmask_small(\n        tmp_inp, tmp_tgt, mask_trn, epochs=epochs, algo=algo, regularizer=reg\n    )\n\n    if self.verbose:\n        self._plot_loss_curves(losses_trn, losses_tst, f\"Unsupervised {self.__class__.__name__} {algo.upper()}\")\n\n    return inp\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.DataScalingBias","title":"DataScalingBias  <code>dataclass</code>","text":"<pre><code>DataScalingBias(scaling_inp: float | NDArray = 1.0, scaling_out: float | NDArray = 1.0, scaling_tgt: float | NDArray = 1.0, bias_inp: float | NDArray = 0.0, bias_out: float | NDArray = 0.0, bias_tgt: float | NDArray = 0.0)\n</code></pre> <p>Data scaling and bias.</p>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.Denoiser","title":"Denoiser","text":"<pre><code>Denoiser(model: int | str | NetworkParams | Module | Mapping, data_scaling_bias: DataScalingBias | None = None, reg_tv_val: float | None = 1e-05, device: str = 'cuda' if is_available() else 'cpu', save_epochs_dir: str | None = None, verbose: bool = True)\n</code></pre> <p>Denoising images.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str | NetworkParams | Module | Mapping | None</code>)           \u2013            <p>Type of neural network to use or a specific network (or state) to use</p> </li> <li> <code>data_scaling_bias</code>               (<code>DataScalingBias | None</code>, default:                   <code>None</code> )           \u2013            <p>Scaling and bias of the input data, by default None</p> </li> <li> <code>reg_tv_val</code>               (<code>float | None</code>, default:                   <code>1e-05</code> )           \u2013            <p>Deep-image prior regularization value, by default 1e-5</p> </li> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"</p> </li> <li> <code>save_epochs_dir</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Directory where to save network states at each epoch. If None disabled, by default None</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to produce verbose output, by default True</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>infer</code>             \u2013              <p>Inference, given an initial stack of images.</p> </li> <li> <code>train_supervised</code>             \u2013              <p>Supervised training.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def __init__(\n    self,\n    model: int | str | NetworkParams | pt.nn.Module | Mapping,\n    data_scaling_bias: DataScalingBias | None = None,\n    reg_tv_val: float | None = 1e-5,\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n    save_epochs_dir: str | None = None,\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"Initialize the noise2noise method.\n\n    Parameters\n    ----------\n    model : str | NetworkParams | pt.nn.Module | Mapping | None\n        Type of neural network to use or a specific network (or state) to use\n    data_scaling_bias : DataScalingBias | None, optional\n        Scaling and bias of the input data, by default None\n    reg_tv_val : float | None, optional\n        Deep-image prior regularization value, by default 1e-5\n    device : str, optional\n        Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"\n    save_epochs_dir : str | None, optional\n        Directory where to save network states at each epoch.\n        If None disabled, by default None\n    verbose : bool, optional\n        Whether to produce verbose output, by default True\n    \"\"\"\n    if isinstance(model, int):\n        if self.save_epochs_dir is None:\n            raise ValueError(\"Directory for saving epochs not specified\")\n\n        model = load_model_state(self.save_epochs_dir, epoch_num=model)\n\n    if isinstance(model, (str, NetworkParams, Mapping, pt.nn.Module)):\n        self.model = create_network(model, device=device)\n    else:\n        raise ValueError(f\"Invalid model {type(model)}\")\n    if verbose:\n        get_num_parameters(self.model, verbose=True)\n\n    self.data_sb = data_scaling_bias\n\n    self.reg_val = reg_tv_val\n    self.device = device\n    self.save_epochs_dir = save_epochs_dir\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.Denoiser.infer","title":"infer","text":"<pre><code>infer(inp: NDArray) -&gt; NDArray\n</code></pre> <p>Inference, given an initial stack of images.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input stack of images</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>The denoised stack of images</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def infer(self, inp: NDArray) -&gt; NDArray:\n    \"\"\"Inference, given an initial stack of images.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input stack of images\n\n    Returns\n    -------\n    NDArray\n        The denoised stack of images\n    \"\"\"\n    # Rescale input\n    if self.data_sb is not None:\n        inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n\n    inp_t = _single_channel_imgs_to_tensor(inp, device=self.device)\n\n    self.model.eval()\n    with pt.inference_mode():\n        out_t: pt.Tensor = self.model(inp_t)\n        output = out_t.to(\"cpu\").numpy().reshape(inp.shape)\n\n    # Rescale output\n    if self.data_sb is not None:\n        output = (output + self.data_sb.bias_out) / self.data_sb.scaling_out\n\n    return output\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.Denoiser.train_supervised","title":"train_supervised","text":"<pre><code>train_supervised(inp: NDArray, tgt: NDArray, epochs: int, tst_inds: Sequence[int] | NDArray, algo: str = 'adam')\n</code></pre> <p>Supervised training.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input images</p> </li> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>The target images</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>Number of training epochs</p> </li> <li> <code>tst_inds</code>               (<code>Sequence[int] | NDArray</code>)           \u2013            <p>The validation set indices</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>Learning algorithm to use, by default \"adam\"</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_supervised(\n    self,\n    inp: NDArray,\n    tgt: NDArray,\n    epochs: int,\n    tst_inds: Sequence[int] | NDArray,\n    algo: str = \"adam\",\n):\n    \"\"\"Supervised training.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input images\n    tgt : NDArray\n        The target images\n    epochs : int\n        Number of training epochs\n    tst_inds : Sequence[int] | NDArray\n        The validation set indices\n    algo : str, optional\n        Learning algorithm to use, by default \"adam\"\n    \"\"\"\n    num_imgs = inp.shape[0]\n    tst_inds = np.array(tst_inds, dtype=int)\n    if np.any(tst_inds &lt; 0) or np.any(tst_inds &gt;= num_imgs):\n        raise ValueError(\n            f\"Each cross-validation index should be greater or equal than 0, and less than the number of images {num_imgs}\"\n        )\n    trn_inds = np.delete(np.arange(num_imgs), obj=tst_inds)\n\n    if tgt.ndim == (inp.ndim - 1):\n        tgt = np.tile(tgt[None, ...], [num_imgs, *np.ones_like(tgt.shape)])\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_supervised(inp, tgt)\n\n    # Rescale the datasets\n    inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n    tgt = tgt * self.data_sb.scaling_tgt - self.data_sb.bias_tgt\n\n    # Create datasets\n    dset_trn = (inp[trn_inds], tgt[trn_inds])\n    dset_tst = (inp[tst_inds], tgt[tst_inds])\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    loss_trn, loss_tst = self._train_selfsimilar(dset_trn, dset_tst, epochs=epochs, algo=algo, regularizer=reg)\n\n    if self.verbose:\n        self._plot_loss_curves(loss_trn, loss_tst, f\"Supervised {algo.upper()}\")\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.N2N","title":"N2N","text":"<pre><code>N2N(model: int | str | NetworkParams | Module | Mapping, data_scaling_bias: DataScalingBias | None = None, reg_tv_val: float | None = 1e-05, device: str = 'cuda' if is_available() else 'cpu', save_epochs_dir: str | None = None, verbose: bool = True)\n</code></pre> <p>               Bases: <code>Denoiser</code></p> <p>Self-supervised denoising from pairs of images.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str | NetworkParams | Module | Mapping | None</code>)           \u2013            <p>Type of neural network to use or a specific network (or state) to use</p> </li> <li> <code>data_scaling_bias</code>               (<code>DataScalingBias | None</code>, default:                   <code>None</code> )           \u2013            <p>Scaling and bias of the input data, by default None</p> </li> <li> <code>reg_tv_val</code>               (<code>float | None</code>, default:                   <code>1e-05</code> )           \u2013            <p>Deep-image prior regularization value, by default 1e-5</p> </li> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"</p> </li> <li> <code>save_epochs_dir</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Directory where to save network states at each epoch. If None disabled, by default None</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to produce verbose output, by default True</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>infer</code>             \u2013              <p>Inference, given an initial stack of images.</p> </li> <li> <code>train_supervised</code>             \u2013              <p>Supervised training.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def __init__(\n    self,\n    model: int | str | NetworkParams | pt.nn.Module | Mapping,\n    data_scaling_bias: DataScalingBias | None = None,\n    reg_tv_val: float | None = 1e-5,\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n    save_epochs_dir: str | None = None,\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"Initialize the noise2noise method.\n\n    Parameters\n    ----------\n    model : str | NetworkParams | pt.nn.Module | Mapping | None\n        Type of neural network to use or a specific network (or state) to use\n    data_scaling_bias : DataScalingBias | None, optional\n        Scaling and bias of the input data, by default None\n    reg_tv_val : float | None, optional\n        Deep-image prior regularization value, by default 1e-5\n    device : str, optional\n        Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"\n    save_epochs_dir : str | None, optional\n        Directory where to save network states at each epoch.\n        If None disabled, by default None\n    verbose : bool, optional\n        Whether to produce verbose output, by default True\n    \"\"\"\n    if isinstance(model, int):\n        if self.save_epochs_dir is None:\n            raise ValueError(\"Directory for saving epochs not specified\")\n\n        model = load_model_state(self.save_epochs_dir, epoch_num=model)\n\n    if isinstance(model, (str, NetworkParams, Mapping, pt.nn.Module)):\n        self.model = create_network(model, device=device)\n    else:\n        raise ValueError(f\"Invalid model {type(model)}\")\n    if verbose:\n        get_num_parameters(self.model, verbose=True)\n\n    self.data_sb = data_scaling_bias\n\n    self.reg_val = reg_tv_val\n    self.device = device\n    self.save_epochs_dir = save_epochs_dir\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.N2N.infer","title":"infer","text":"<pre><code>infer(inp: NDArray) -&gt; NDArray\n</code></pre> <p>Inference, given an initial stack of images.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input stack of images</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>The denoised stack of images</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def infer(self, inp: NDArray) -&gt; NDArray:\n    \"\"\"Inference, given an initial stack of images.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input stack of images\n\n    Returns\n    -------\n    NDArray\n        The denoised stack of images\n    \"\"\"\n    # Rescale input\n    if self.data_sb is not None:\n        inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n\n    inp_t = _single_channel_imgs_to_tensor(inp, device=self.device)\n\n    self.model.eval()\n    with pt.inference_mode():\n        out_t: pt.Tensor = self.model(inp_t)\n        output = out_t.to(\"cpu\").numpy().reshape(inp.shape)\n\n    # Rescale output\n    if self.data_sb is not None:\n        output = (output + self.data_sb.bias_out) / self.data_sb.scaling_out\n\n    return output\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.N2N.train_supervised","title":"train_supervised","text":"<pre><code>train_supervised(inp: NDArray, tgt: NDArray, epochs: int, tst_inds: Sequence[int] | NDArray, algo: str = 'adam')\n</code></pre> <p>Supervised training.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input images</p> </li> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>The target images</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>Number of training epochs</p> </li> <li> <code>tst_inds</code>               (<code>Sequence[int] | NDArray</code>)           \u2013            <p>The validation set indices</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>Learning algorithm to use, by default \"adam\"</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_supervised(\n    self,\n    inp: NDArray,\n    tgt: NDArray,\n    epochs: int,\n    tst_inds: Sequence[int] | NDArray,\n    algo: str = \"adam\",\n):\n    \"\"\"Supervised training.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input images\n    tgt : NDArray\n        The target images\n    epochs : int\n        Number of training epochs\n    tst_inds : Sequence[int] | NDArray\n        The validation set indices\n    algo : str, optional\n        Learning algorithm to use, by default \"adam\"\n    \"\"\"\n    num_imgs = inp.shape[0]\n    tst_inds = np.array(tst_inds, dtype=int)\n    if np.any(tst_inds &lt; 0) or np.any(tst_inds &gt;= num_imgs):\n        raise ValueError(\n            f\"Each cross-validation index should be greater or equal than 0, and less than the number of images {num_imgs}\"\n        )\n    trn_inds = np.delete(np.arange(num_imgs), obj=tst_inds)\n\n    if tgt.ndim == (inp.ndim - 1):\n        tgt = np.tile(tgt[None, ...], [num_imgs, *np.ones_like(tgt.shape)])\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_supervised(inp, tgt)\n\n    # Rescale the datasets\n    inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n    tgt = tgt * self.data_sb.scaling_tgt - self.data_sb.bias_tgt\n\n    # Create datasets\n    dset_trn = (inp[trn_inds], tgt[trn_inds])\n    dset_tst = (inp[tst_inds], tgt[tst_inds])\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    loss_trn, loss_tst = self._train_selfsimilar(dset_trn, dset_tst, epochs=epochs, algo=algo, regularizer=reg)\n\n    if self.verbose:\n        self._plot_loss_curves(loss_trn, loss_tst, f\"Supervised {algo.upper()}\")\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.N2V","title":"N2V","text":"<pre><code>N2V(model: int | str | NetworkParams | Module | Mapping, data_scaling_bias: DataScalingBias | None = None, reg_tv_val: float | None = 1e-05, device: str = 'cuda' if is_available() else 'cpu', save_epochs_dir: str | None = None, verbose: bool = True)\n</code></pre> <p>               Bases: <code>Denoiser</code></p> <p>Self-supervised denoising from single images.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str | NetworkParams | Module | Mapping | None</code>)           \u2013            <p>Type of neural network to use or a specific network (or state) to use</p> </li> <li> <code>data_scaling_bias</code>               (<code>DataScalingBias | None</code>, default:                   <code>None</code> )           \u2013            <p>Scaling and bias of the input data, by default None</p> </li> <li> <code>reg_tv_val</code>               (<code>float | None</code>, default:                   <code>1e-05</code> )           \u2013            <p>Deep-image prior regularization value, by default 1e-5</p> </li> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"</p> </li> <li> <code>save_epochs_dir</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Directory where to save network states at each epoch. If None disabled, by default None</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to produce verbose output, by default True</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>infer</code>             \u2013              <p>Inference, given an initial stack of images.</p> </li> <li> <code>train_selfsupervised</code>             \u2013              <p>Self-supervised training.</p> </li> <li> <code>train_supervised</code>             \u2013              <p>Supervised training.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def __init__(\n    self,\n    model: int | str | NetworkParams | pt.nn.Module | Mapping,\n    data_scaling_bias: DataScalingBias | None = None,\n    reg_tv_val: float | None = 1e-5,\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n    save_epochs_dir: str | None = None,\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"Initialize the noise2noise method.\n\n    Parameters\n    ----------\n    model : str | NetworkParams | pt.nn.Module | Mapping | None\n        Type of neural network to use or a specific network (or state) to use\n    data_scaling_bias : DataScalingBias | None, optional\n        Scaling and bias of the input data, by default None\n    reg_tv_val : float | None, optional\n        Deep-image prior regularization value, by default 1e-5\n    device : str, optional\n        Device to use, by default \"cuda\" if cuda is available, otherwise \"cpu\"\n    save_epochs_dir : str | None, optional\n        Directory where to save network states at each epoch.\n        If None disabled, by default None\n    verbose : bool, optional\n        Whether to produce verbose output, by default True\n    \"\"\"\n    if isinstance(model, int):\n        if self.save_epochs_dir is None:\n            raise ValueError(\"Directory for saving epochs not specified\")\n\n        model = load_model_state(self.save_epochs_dir, epoch_num=model)\n\n    if isinstance(model, (str, NetworkParams, Mapping, pt.nn.Module)):\n        self.model = create_network(model, device=device)\n    else:\n        raise ValueError(f\"Invalid model {type(model)}\")\n    if verbose:\n        get_num_parameters(self.model, verbose=True)\n\n    self.data_sb = data_scaling_bias\n\n    self.reg_val = reg_tv_val\n    self.device = device\n    self.save_epochs_dir = save_epochs_dir\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.N2V.infer","title":"infer","text":"<pre><code>infer(inp: NDArray) -&gt; NDArray\n</code></pre> <p>Inference, given an initial stack of images.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input stack of images</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>           \u2013            <p>The denoised stack of images</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def infer(self, inp: NDArray) -&gt; NDArray:\n    \"\"\"Inference, given an initial stack of images.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input stack of images\n\n    Returns\n    -------\n    NDArray\n        The denoised stack of images\n    \"\"\"\n    # Rescale input\n    if self.data_sb is not None:\n        inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n\n    inp_t = _single_channel_imgs_to_tensor(inp, device=self.device)\n\n    self.model.eval()\n    with pt.inference_mode():\n        out_t: pt.Tensor = self.model(inp_t)\n        output = out_t.to(\"cpu\").numpy().reshape(inp.shape)\n\n    # Rescale output\n    if self.data_sb is not None:\n        output = (output + self.data_sb.bias_out) / self.data_sb.scaling_out\n\n    return output\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.N2V.train_selfsupervised","title":"train_selfsupervised","text":"<pre><code>train_selfsupervised(inp: NDArray, epochs: int, tst_inds: Sequence[int] | NDArray, mask_shape: int | Sequence[int] | NDArray = 1, ratio_blind_spot: float = 0.015, algo: str = 'adam')\n</code></pre> <p>Self-supervised training.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input images, which will also be targets</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>Number of training epochs</p> </li> <li> <code>tst_inds</code>               (<code>Sequence[int] | NDArray</code>)           \u2013            <p>The validation set indices</p> </li> <li> <code>mask_shape</code>               (<code>int | Sequence[int] | NDArray</code>, default:                   <code>1</code> )           \u2013            <p>Shape of the blind spot mask, by default 1.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>Learning algorithm to use, by default \"adam\"</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_selfsupervised(\n    self,\n    inp: NDArray,\n    epochs: int,\n    tst_inds: Sequence[int] | NDArray,\n    mask_shape: int | Sequence[int] | NDArray = 1,\n    ratio_blind_spot: float = 0.015,\n    algo: str = \"adam\",\n):\n    \"\"\"Self-supervised training.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input images, which will also be targets\n    epochs : int\n        Number of training epochs\n    tst_inds : Sequence[int] | NDArray\n        The validation set indices\n    mask_shape : int | Sequence[int] | NDArray\n        Shape of the blind spot mask, by default 1.\n    algo : str, optional\n        Learning algorithm to use, by default \"adam\"\n    \"\"\"\n    num_imgs = inp.shape[0]\n    tst_inds = np.array(tst_inds, dtype=int)\n    if np.any(tst_inds &lt; 0) or np.any(tst_inds &gt;= num_imgs):\n        raise ValueError(\n            f\"Each cross-validation index should be greater or equal than 0, and less than the number of images {num_imgs}\"\n        )\n    trn_inds = np.delete(np.arange(num_imgs), obj=tst_inds)\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_selfsupervised(inp)\n\n    # Rescale the datasets\n    inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n\n    inp_trn = inp[trn_inds]\n    inp_tst = inp[tst_inds]\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    losses_trn, losses_tst = self._train_n2v_pixelmask_small(\n        inp_trn,\n        inp_tst,\n        epochs=epochs,\n        mask_shape=mask_shape,\n        ratio_blind_spot=ratio_blind_spot,\n        algo=algo,\n        regularizer=reg,\n    )\n\n    self._plot_loss_curves(losses_trn, losses_tst, f\"Self-supervised {self.__class__.__name__} {algo.upper()}\")\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.N2V.train_supervised","title":"train_supervised","text":"<pre><code>train_supervised(inp: NDArray, tgt: NDArray, epochs: int, tst_inds: Sequence[int] | NDArray, algo: str = 'adam')\n</code></pre> <p>Supervised training.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>The input images</p> </li> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>The target images</p> </li> <li> <code>epochs</code>               (<code>int</code>)           \u2013            <p>Number of training epochs</p> </li> <li> <code>tst_inds</code>               (<code>Sequence[int] | NDArray</code>)           \u2013            <p>The validation set indices</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>Learning algorithm to use, by default \"adam\"</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def train_supervised(\n    self,\n    inp: NDArray,\n    tgt: NDArray,\n    epochs: int,\n    tst_inds: Sequence[int] | NDArray,\n    algo: str = \"adam\",\n):\n    \"\"\"Supervised training.\n\n    Parameters\n    ----------\n    inp : NDArray\n        The input images\n    tgt : NDArray\n        The target images\n    epochs : int\n        Number of training epochs\n    tst_inds : Sequence[int] | NDArray\n        The validation set indices\n    algo : str, optional\n        Learning algorithm to use, by default \"adam\"\n    \"\"\"\n    num_imgs = inp.shape[0]\n    tst_inds = np.array(tst_inds, dtype=int)\n    if np.any(tst_inds &lt; 0) or np.any(tst_inds &gt;= num_imgs):\n        raise ValueError(\n            f\"Each cross-validation index should be greater or equal than 0, and less than the number of images {num_imgs}\"\n        )\n    trn_inds = np.delete(np.arange(num_imgs), obj=tst_inds)\n\n    if tgt.ndim == (inp.ndim - 1):\n        tgt = np.tile(tgt[None, ...], [num_imgs, *np.ones_like(tgt.shape)])\n\n    if self.data_sb is None:\n        self.data_sb = compute_scaling_supervised(inp, tgt)\n\n    # Rescale the datasets\n    inp = inp * self.data_sb.scaling_inp - self.data_sb.bias_inp\n    tgt = tgt * self.data_sb.scaling_tgt - self.data_sb.bias_tgt\n\n    # Create datasets\n    dset_trn = (inp[trn_inds], tgt[trn_inds])\n    dset_tst = (inp[tst_inds], tgt[tst_inds])\n\n    reg = losses.LossTGV(self.reg_val, reduction=\"mean\") if self.reg_val is not None else None\n    loss_trn, loss_tst = self._train_selfsimilar(dset_trn, dset_tst, epochs=epochs, algo=algo, regularizer=reg)\n\n    if self.verbose:\n        self._plot_loss_curves(loss_trn, loss_tst, f\"Supervised {algo.upper()}\")\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.compute_scaling_selfsupervised","title":"compute_scaling_selfsupervised","text":"<pre><code>compute_scaling_selfsupervised(inp: NDArray) -&gt; DataScalingBias\n</code></pre> <p>Compute input data scaling and bias for self-supervised learning.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>Input data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataScalingBias</code>           \u2013            <p>An instance of DataScalingBias containing the computed scaling and bias values.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def compute_scaling_selfsupervised(inp: NDArray) -&gt; DataScalingBias:\n    \"\"\"\n    Compute input data scaling and bias for self-supervised learning.\n\n    Parameters\n    ----------\n    inp : NDArray\n        Input data.\n\n    Returns\n    -------\n    DataScalingBias\n        An instance of DataScalingBias containing the computed scaling and bias values.\n    \"\"\"\n    range_vals_inp = _get_normalization(inp, percentile=0.001)\n\n    sb = DataScalingBias()\n    sb.scaling_inp = 1 / (range_vals_inp[1] - range_vals_inp[0])\n    sb.scaling_out = sb.scaling_tgt = sb.scaling_inp\n\n    sb.bias_inp = range_vals_inp[2] * sb.scaling_inp\n    sb.bias_out = sb.bias_tgt = sb.bias_inp\n\n    return sb\n</code></pre>"},{"location":"reference/autoden/algorithms/#autoden.algorithms.compute_scaling_supervised","title":"compute_scaling_supervised","text":"<pre><code>compute_scaling_supervised(inp: NDArray, tgt: NDArray) -&gt; DataScalingBias\n</code></pre> <p>Compute input and target data scaling and bias for supervised learning.</p> <p>Parameters:</p> <ul> <li> <code>inp</code>               (<code>NDArray</code>)           \u2013            <p>Input data.</p> </li> <li> <code>tgt</code>               (<code>NDArray</code>)           \u2013            <p>Target data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataScalingBias</code>           \u2013            <p>An instance of DataScalingBias containing the computed scaling and bias values.</p> </li> </ul> Source code in <code>src/autoden/algorithms.py</code> <pre><code>def compute_scaling_supervised(inp: NDArray, tgt: NDArray) -&gt; DataScalingBias:\n    \"\"\"\n    Compute input and target data scaling and bias for supervised learning.\n\n    Parameters\n    ----------\n    inp : NDArray\n        Input data.\n    tgt : NDArray\n        Target data.\n\n    Returns\n    -------\n    DataScalingBias\n        An instance of DataScalingBias containing the computed scaling and bias values.\n    \"\"\"\n    range_vals_inp = _get_normalization(inp, percentile=0.001)\n    range_vals_tgt = _get_normalization(tgt, percentile=0.001)\n\n    sb = DataScalingBias()\n    sb.scaling_inp = 1 / (range_vals_inp[1] - range_vals_inp[0])\n    sb.scaling_tgt = 1 / (range_vals_tgt[1] - range_vals_tgt[0])\n    sb.scaling_out = sb.scaling_tgt\n\n    sb.bias_inp = range_vals_inp[2] * sb.scaling_inp\n    sb.bias_tgt = range_vals_tgt[2] * sb.scaling_tgt\n    sb.bias_out = sb.bias_tgt\n\n    return sb\n</code></pre>"},{"location":"reference/autoden/cli/","title":"autoden.cli","text":""},{"location":"reference/autoden/cli/#autoden.cli","title":"cli","text":"<p>Module that contains the command line application.</p> <p>Functions:</p> <ul> <li> <code>get_parser</code>             \u2013              <p>Return the CLI argument parser.</p> </li> <li> <code>main</code>             \u2013              <p>Run the main program.</p> </li> </ul>"},{"location":"reference/autoden/cli/#autoden.cli.get_parser","title":"get_parser","text":"<pre><code>get_parser() -&gt; ArgumentParser\n</code></pre> <p>Return the CLI argument parser.</p> <p>Returns:</p> <ul> <li> <code>ArgumentParser</code>           \u2013            <p>An argparse parser.</p> </li> </ul> Source code in <code>src/autoden/cli.py</code> <pre><code>def get_parser() -&gt; argparse.ArgumentParser:\n    \"\"\"\n    Return the CLI argument parser.\n\n    Returns\n    -------\n    argparse.ArgumentParser\n        An argparse parser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"autoden\",\n        description=\"Denoise the given images, using deep-learning-based unsupervised or self-supervised algorithms.\",\n    )\n    parser.add_argument(\"algorithm\", choices=[\"N2N\", \"N2V\", \"DIP\"], help=\"Denoising algorithm to use\")\n    parser.add_argument(\n        \"--epochs\",\n        \"-e\",\n        type=int,\n        help=f\"Number of epochs to use, by default {DEFAULT_EPOCHS}.\",\n        metavar=\"E\",\n        default=DEFAULT_EPOCHS,\n    )\n    parser.add_argument(\n        \"--unet-levels\",\n        \"-l\",\n        type=int,\n        help=f\"Number of UNet levels to use, by default: {NetworkParamsUNet.DEFAULT_LEVELS}.\",\n        default=NetworkParamsUNet.DEFAULT_LEVELS,\n        metavar=\"L\",\n    )\n    parser.add_argument(\n        \"--unet-features\",\n        \"-f\",\n        type=int,\n        help=f\"Number of UNet features to use, by default: {NetworkParamsUNet.DEFAULT_FEATURES}.\",\n        default=NetworkParamsUNet.DEFAULT_FEATURES,\n        metavar=\"F\",\n    )\n    parser.add_argument(\n        \"--regularization\",\n        \"-r\",\n        type=float,\n        help=f\"Total Variation regularization value, by default: {DEFAULT_TV_VAL}.\",\n        default=DEFAULT_TV_VAL,\n        metavar=\"R\",\n    )\n    parser.add_argument(\"src_file\", nargs=\"+\", help=\"Path of each input image.\", type=argparse.FileType(\"rb\"))\n    parser.add_argument(\"dst_file\", help=\"Path of the output image.\", type=argparse.FileType(\"wb\"))\n    parser.add_argument(\"-V\", \"--version\", action=\"version\", version=f\"%(prog)s {debug.get_version()}\")\n    parser.add_argument(\"--debug-info\", action=_DebugInfo, help=\"Print debug information.\")\n    return parser\n</code></pre>"},{"location":"reference/autoden/cli/#autoden.cli.main","title":"main","text":"<pre><code>main(args: list[str] | None = None) -&gt; int\n</code></pre> <p>Run the main program.</p> <p>This function is executed when you type <code>autoden</code> or <code>python -m autoden</code>.</p> <p>Parameters:</p> <ul> <li> <code>args</code>               (<code>list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Arguments passed from the command line, by default None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>An exit code.</p> </li> </ul> Source code in <code>src/autoden/cli.py</code> <pre><code>def main(args: list[str] | None = None) -&gt; int:\n    \"\"\"\n    Run the main program.\n\n    This function is executed when you type `autoden` or `python -m autoden`.\n\n    Parameters\n    ----------\n    args : list[str] | None\n        Arguments passed from the command line, by default None.\n\n    Returns\n    -------\n    int\n        An exit code.\n    \"\"\"\n    parser = get_parser()\n    opts = parser.parse_args(args=args)\n    # print(opts)  # noqa: WPS421 (side-effect in main is fine)\n\n    inp_imgs = [iio.imread(f) for f in opts.src_file]\n    if any(x.ndim &gt; 2 for x in inp_imgs):\n        print(\"Color images not supported, yet.\")\n        return 1\n    inp_imgs_stack = np.stack(inp_imgs, axis=0)\n\n    net_pars = NetworkParamsUNet(n_levels=opts.unet_levels, n_features=opts.unet_features)\n\n    if opts.algorithm.upper() == \"DIP\":\n        algo = DIP(model=net_pars, reg_tv_val=opts.regularization)\n        inp_img = algo.train_unsupervised(inp_imgs_stack, epochs=opts.epochs)\n        out_img = algo.infer(inp_img)\n    elif opts.algorithm.upper() == \"N2N\":\n        if len(inp_imgs) &lt; 2:\n            print(f\"Not enough input images, only {len(inp_imgs)} were passed.\")\n            return 1\n\n        algo = N2N(model=net_pars, reg_tv_val=opts.regularization)\n        algo.train_selfsupervised(inp_imgs_stack, epochs=opts.epochs)\n        out_img = algo.infer(inp_imgs_stack)\n    else:\n        print(f\"Not implemented support for algorithm {opts.algorithm} in command-line, yet.\")\n        return 1\n\n    iio.imwrite(opts.dst_file, out_img)\n    return 0\n</code></pre>"},{"location":"reference/autoden/debug/","title":"autoden.debug","text":""},{"location":"reference/autoden/debug/#autoden.debug","title":"debug","text":"<p>Debugging utilities.</p> <p>Classes:</p> <ul> <li> <code>Environment</code>           \u2013            <p>Dataclass to store environment information.</p> </li> <li> <code>Package</code>           \u2013            <p>Dataclass describing a Python package.</p> </li> <li> <code>Variable</code>           \u2013            <p>Dataclass describing an environment variable.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>get_debug_info</code>             \u2013              <p>Get debug/environment information.</p> </li> <li> <code>get_version</code>             \u2013              <p>Get version of the given distribution.</p> </li> <li> <code>print_debug_info</code>             \u2013              <p>Print debug/environment information.</p> </li> </ul>"},{"location":"reference/autoden/debug/#autoden.debug.Environment","title":"Environment  <code>dataclass</code>","text":"<pre><code>Environment(interpreter_name: str, interpreter_version: str, interpreter_path: str, platform: str, packages: list[Package], variables: list[Variable])\n</code></pre> <p>Dataclass to store environment information.</p> <p>Attributes:</p> <ul> <li> <code>interpreter_name</code>               (<code>str</code>)           \u2013            <p>Python interpreter name.</p> </li> <li> <code>interpreter_path</code>               (<code>str</code>)           \u2013            <p>Path to Python executable.</p> </li> <li> <code>interpreter_version</code>               (<code>str</code>)           \u2013            <p>Python interpreter version.</p> </li> <li> <code>packages</code>               (<code>list[Package]</code>)           \u2013            <p>Installed packages.</p> </li> <li> <code>platform</code>               (<code>str</code>)           \u2013            <p>Operating System.</p> </li> <li> <code>variables</code>               (<code>list[Variable]</code>)           \u2013            <p>Environment variables.</p> </li> </ul>"},{"location":"reference/autoden/debug/#autoden.debug.Environment.interpreter_name","title":"interpreter_name  <code>instance-attribute</code>","text":"<pre><code>interpreter_name: str\n</code></pre> <p>Python interpreter name.</p>"},{"location":"reference/autoden/debug/#autoden.debug.Environment.interpreter_path","title":"interpreter_path  <code>instance-attribute</code>","text":"<pre><code>interpreter_path: str\n</code></pre> <p>Path to Python executable.</p>"},{"location":"reference/autoden/debug/#autoden.debug.Environment.interpreter_version","title":"interpreter_version  <code>instance-attribute</code>","text":"<pre><code>interpreter_version: str\n</code></pre> <p>Python interpreter version.</p>"},{"location":"reference/autoden/debug/#autoden.debug.Environment.packages","title":"packages  <code>instance-attribute</code>","text":"<pre><code>packages: list[Package]\n</code></pre> <p>Installed packages.</p>"},{"location":"reference/autoden/debug/#autoden.debug.Environment.platform","title":"platform  <code>instance-attribute</code>","text":"<pre><code>platform: str\n</code></pre> <p>Operating System.</p>"},{"location":"reference/autoden/debug/#autoden.debug.Environment.variables","title":"variables  <code>instance-attribute</code>","text":"<pre><code>variables: list[Variable]\n</code></pre> <p>Environment variables.</p>"},{"location":"reference/autoden/debug/#autoden.debug.Package","title":"Package  <code>dataclass</code>","text":"<pre><code>Package(name: str, version: str)\n</code></pre> <p>Dataclass describing a Python package.</p> <p>Attributes:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>Package name.</p> </li> <li> <code>version</code>               (<code>str</code>)           \u2013            <p>Package version.</p> </li> </ul>"},{"location":"reference/autoden/debug/#autoden.debug.Package.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>Package name.</p>"},{"location":"reference/autoden/debug/#autoden.debug.Package.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version: str\n</code></pre> <p>Package version.</p>"},{"location":"reference/autoden/debug/#autoden.debug.Variable","title":"Variable  <code>dataclass</code>","text":"<pre><code>Variable(name: str, value: str)\n</code></pre> <p>Dataclass describing an environment variable.</p> <p>Attributes:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>Variable name.</p> </li> <li> <code>value</code>               (<code>str</code>)           \u2013            <p>Variable value.</p> </li> </ul>"},{"location":"reference/autoden/debug/#autoden.debug.Variable.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>Variable name.</p>"},{"location":"reference/autoden/debug/#autoden.debug.Variable.value","title":"value  <code>instance-attribute</code>","text":"<pre><code>value: str\n</code></pre> <p>Variable value.</p>"},{"location":"reference/autoden/debug/#autoden.debug.get_debug_info","title":"get_debug_info","text":"<pre><code>get_debug_info() -&gt; Environment\n</code></pre> <p>Get debug/environment information.</p> <p>Returns:     Environment information.</p> Source code in <code>src/autoden/debug.py</code> <pre><code>def get_debug_info() -&gt; Environment:\n    \"\"\"Get debug/environment information.\n\n    Returns:\n        Environment information.\n    \"\"\"\n    py_name, py_version = _interpreter_name_version()\n    packages = [\"auto-denoise\"]\n    variables = [\"PYTHONPATH\", *[var for var in os.environ if var.startswith(\"AUTO_DENOISE\")]]\n    return Environment(\n        interpreter_name=py_name,\n        interpreter_version=py_version,\n        interpreter_path=sys.executable,\n        platform=platform.platform(),\n        variables=[Variable(var, val) for var in variables if (val := os.getenv(var))],\n        packages=[Package(pkg, get_version(pkg)) for pkg in packages],\n    )\n</code></pre>"},{"location":"reference/autoden/debug/#autoden.debug.get_version","title":"get_version","text":"<pre><code>get_version(dist: str = 'auto-denoise') -&gt; str\n</code></pre> <p>Get version of the given distribution.</p> <p>Parameters:     dist: A distribution name.</p> <p>Returns:     A version number.</p> Source code in <code>src/autoden/debug.py</code> <pre><code>def get_version(dist: str = \"auto-denoise\") -&gt; str:\n    \"\"\"Get version of the given distribution.\n\n    Parameters:\n        dist: A distribution name.\n\n    Returns:\n        A version number.\n    \"\"\"\n    try:\n        return metadata.version(dist)\n    except metadata.PackageNotFoundError:\n        return \"0.0.0\"\n</code></pre>"},{"location":"reference/autoden/debug/#autoden.debug.print_debug_info","title":"print_debug_info","text":"<pre><code>print_debug_info() -&gt; None\n</code></pre> <p>Print debug/environment information.</p> Source code in <code>src/autoden/debug.py</code> <pre><code>def print_debug_info() -&gt; None:\n    \"\"\"Print debug/environment information.\"\"\"\n    info = get_debug_info()\n    print(f\"- __System__: {info.platform}\")\n    print(f\"- __Python__: {info.interpreter_name} {info.interpreter_version} ({info.interpreter_path})\")\n    print(\"- __Environment variables__:\")\n    for var in info.variables:\n        print(f\"  - `{var.name}`: `{var.value}`\")\n    print(\"- __Installed packages__:\")\n    for pkg in info.packages:\n        print(f\"  - `{pkg.name}` v{pkg.version}\")\n</code></pre>"},{"location":"reference/autoden/io/","title":"autoden.io","text":""},{"location":"reference/autoden/io/#autoden.io","title":"io","text":"<p>IO module.</p> <p>Functions:</p> <ul> <li> <code>load_model_state</code>             \u2013              <p>Load a model from disk.</p> </li> <li> <code>save_model_state</code>             \u2013              <p>Save a model's state to disk.</p> </li> </ul>"},{"location":"reference/autoden/io/#autoden.io.load_model_state","title":"load_model_state","text":"<pre><code>load_model_state(save_epochs_dir: str | Path, epoch_num: int | None = None) -&gt; Mapping\n</code></pre> <p>Load a model from disk.</p> <p>Parameters:</p> <ul> <li> <code>save_epochs_dir</code>               (<code>str | Path</code>)           \u2013            <p>The director where the models are saved</p> </li> <li> <code>epoch_num</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The epoch number or if None/-1 the best state will be loaded, by default None</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Mapping</code>           \u2013            <p>The loaded model state and possibly an optimizer state.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>When the directory does not exist or the requested model is not available.</p> </li> </ul> Source code in <code>src/autoden/io.py</code> <pre><code>def load_model_state(save_epochs_dir: str | Path, epoch_num: int | None = None) -&gt; Mapping:\n    \"\"\"Load a model from disk.\n\n    Parameters\n    ----------\n    save_epochs_dir : str | Path\n        The director where the models are saved\n    epoch_num : int | None, optional\n        The epoch number or if None/-1 the best state will be loaded, by default None\n\n    Returns\n    -------\n    Mapping\n        The loaded model state and possibly an optimizer state.\n\n    Raises\n    ------\n    ValueError\n        When the directory does not exist or the requested model is not available.\n    \"\"\"\n    epochs_base_path = Path(save_epochs_dir) / \"weights\"\n    if not epochs_base_path.exists():\n        raise ValueError(f\"Directory of the model state {epochs_base_path} does not exist!\")\n\n    if epoch_num is None or epoch_num == -1:\n        state_path = epochs_base_path / \"weights.pt\"\n    else:\n        state_path = epochs_base_path / f\"weights_epoch_{epoch_num}.pt\"\n    if not state_path.exists():\n        raise ValueError(f\"Model state {state_path} does not exist!\")\n\n    print(f\"Loading state path: {state_path}\")\n    return pt.load(state_path)\n</code></pre>"},{"location":"reference/autoden/io/#autoden.io.save_model_state","title":"save_model_state","text":"<pre><code>save_model_state(save_epochs_dir: str | Path, epoch_num: int, model: Module, optim_state: Mapping | None = None, is_best: bool = False) -&gt; None\n</code></pre> <p>Save a model's state to disk.</p> <p>This function saves the state of a model and optionally its optimizer to disk. The model state is saved in a directory specified by <code>save_epochs_dir</code>. If <code>is_best</code> is True, the model state is saved as \"weights.pt\". Otherwise, it is saved with a filename that includes the epoch number.</p> <p>Parameters:</p> <ul> <li> <code>save_epochs_dir</code>               (<code>str | Path</code>)           \u2013            <p>The directory where to save the model state.</p> </li> <li> <code>epoch_num</code>               (<code>int</code>)           \u2013            <p>The epoch number.</p> </li> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The model whose state is to be saved.</p> </li> <li> <code>optim_state</code>               (<code>Mapping</code>, default:                   <code>None</code> )           \u2013            <p>The optimizer state to save, by default None.</p> </li> <li> <code>is_best</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether it is the best fitted model, by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            </li> </ul> Source code in <code>src/autoden/io.py</code> <pre><code>def save_model_state(\n    save_epochs_dir: str | Path,\n    epoch_num: int,\n    model: Module,\n    optim_state: Mapping | None = None,\n    is_best: bool = False,\n) -&gt; None:\n    \"\"\"Save a model's state to disk.\n\n    This function saves the state of a model and optionally its optimizer to disk.\n    The model state is saved in a directory specified by `save_epochs_dir`. If\n    `is_best` is True, the model state is saved as \"weights.pt\". Otherwise, it is\n    saved with a filename that includes the epoch number.\n\n    Parameters\n    ----------\n    save_epochs_dir : str | Path\n        The directory where to save the model state.\n    epoch_num : int\n        The epoch number.\n    model : Module\n        The model whose state is to be saved.\n    optim_state : Mapping, optional\n        The optimizer state to save, by default None.\n    is_best : bool, optional\n        Whether it is the best fitted model, by default False.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    epochs_base_path = Path(save_epochs_dir) / \"weights\"\n    epochs_base_path.mkdir(parents=True, exist_ok=True)\n\n    pt.save(\n        {\"model\": model.__class__.__name__, \"epoch\": epoch_num, \"state_dict\": model.state_dict(), \"optimizer\": optim_state},\n        epochs_base_path / (\"weights.pt\" if is_best else f\"weights_epoch_{epoch_num}.pt\"),\n    )\n</code></pre>"},{"location":"reference/autoden/losses/","title":"autoden.losses","text":""},{"location":"reference/autoden/losses/#autoden.losses","title":"losses","text":"<p>Data losses definitions.</p> <p>Classes:</p> <ul> <li> <code>LossRegularizer</code>           \u2013            <p>Base class for the regularizer losses.</p> </li> <li> <code>LossTGV</code>           \u2013            <p>Total Generalized Variation loss function.</p> </li> <li> <code>LossTV</code>           \u2013            <p>Total Variation loss function.</p> </li> </ul>"},{"location":"reference/autoden/losses/#autoden.losses.LossRegularizer","title":"LossRegularizer","text":"<p>               Bases: <code>MSELoss</code></p> <p>Base class for the regularizer losses.</p>"},{"location":"reference/autoden/losses/#autoden.losses.LossTGV","title":"LossTGV","text":"<pre><code>LossTGV(lambda_val: float, size_average=None, reduce=None, reduction: str = 'mean', isotropic: bool = True, ndims: int = 2)\n</code></pre> <p>               Bases: <code>LossTV</code></p> <p>Total Generalized Variation loss function.</p> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Compute total variation statistics on current batch.</p> </li> </ul> Source code in <code>src/autoden/losses.py</code> <pre><code>def __init__(\n    self,\n    lambda_val: float,\n    size_average=None,\n    reduce=None,\n    reduction: str = \"mean\",\n    isotropic: bool = True,\n    ndims: int = 2,\n) -&gt; None:\n    super().__init__(size_average, reduce, reduction)\n    self.lambda_val = lambda_val\n    self.isotropic = isotropic\n    self.ndims = ndims\n</code></pre>"},{"location":"reference/autoden/losses/#autoden.losses.LossTGV.forward","title":"forward","text":"<pre><code>forward(img: Tensor) -&gt; Tensor\n</code></pre> <p>Compute total variation statistics on current batch.</p> Source code in <code>src/autoden/losses.py</code> <pre><code>def forward(self, img: pt.Tensor) -&gt; pt.Tensor:\n    \"\"\"Compute total variation statistics on current batch.\"\"\"\n    self._check_input_tensor(img)\n    axes = list(range(-(self.ndims + 1), 0))\n\n    diffs = [_differentiate(img, dim=dim) for dim in range(-self.ndims, 0)]\n    diffdiffs = [_differentiate(d, dim=dim) for dim in range(-self.ndims, 0) for d in diffs]\n\n    if self.isotropic:\n        tv_val = pt.sqrt(pt.stack([pt.pow(d, 2) for d in diffs], dim=0).sum(dim=0))\n        jac_val = pt.sqrt(pt.stack([pt.pow(d, 2) for d in diffdiffs], dim=0).sum(dim=0))\n    else:\n        tv_val = pt.stack([d.abs() for d in diffs], dim=0).sum(dim=0)\n        jac_val = pt.stack([d.abs() for d in diffdiffs], dim=0).sum(dim=0)\n\n    return self.lambda_val * (tv_val.sum(axes).mean() + jac_val.sum(axes).mean() / 4)\n</code></pre>"},{"location":"reference/autoden/losses/#autoden.losses.LossTV","title":"LossTV","text":"<pre><code>LossTV(lambda_val: float, size_average=None, reduce=None, reduction: str = 'mean', isotropic: bool = True, ndims: int = 2)\n</code></pre> <p>               Bases: <code>LossRegularizer</code></p> <p>Total Variation loss function.</p> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Compute total variation statistics on current batch.</p> </li> </ul> Source code in <code>src/autoden/losses.py</code> <pre><code>def __init__(\n    self,\n    lambda_val: float,\n    size_average=None,\n    reduce=None,\n    reduction: str = \"mean\",\n    isotropic: bool = True,\n    ndims: int = 2,\n) -&gt; None:\n    super().__init__(size_average, reduce, reduction)\n    self.lambda_val = lambda_val\n    self.isotropic = isotropic\n    self.ndims = ndims\n</code></pre>"},{"location":"reference/autoden/losses/#autoden.losses.LossTV.forward","title":"forward","text":"<pre><code>forward(img: Tensor) -&gt; Tensor\n</code></pre> <p>Compute total variation statistics on current batch.</p> Source code in <code>src/autoden/losses.py</code> <pre><code>def forward(self, img: pt.Tensor) -&gt; pt.Tensor:\n    \"\"\"Compute total variation statistics on current batch.\"\"\"\n    self._check_input_tensor(img)\n    axes = list(range(-(self.ndims + 1), 0))\n\n    diffs = [_differentiate(img, dim=dim) for dim in range(-self.ndims, 0)]\n    if self.isotropic:\n        tv_val = pt.sqrt(pt.stack([pt.pow(d, 2) for d in diffs], dim=0).sum(dim=0))\n    else:\n        tv_val = pt.stack([d.abs() for d in diffs], dim=0).sum(dim=0)\n\n    return self.lambda_val * tv_val.sum(axes).mean()\n</code></pre>"},{"location":"reference/autoden/models/","title":"autoden.models","text":""},{"location":"reference/autoden/models/#autoden.models","title":"models","text":"<p>Models sub-package.</p> <p>Implementation of models like DnCNN, MS-D net, and UNet.</p> <p>Adapted from: https://github.com/ahendriksen/noise2inverse</p> <p>Modules:</p> <ul> <li> <code>config</code>           \u2013            <p>High level definition of CNN architectures.</p> </li> <li> <code>dncnn</code>           \u2013            </li> <li> <code>msd</code>           \u2013            <p>Module implementing MS-D net.</p> </li> <li> <code>param_utils</code>           \u2013            <p>This module provides utility functions for handling PyTorch models, including</p> </li> <li> <code>unet</code>           \u2013            <p>Implementation of a flexible U-net.</p> </li> </ul>"},{"location":"reference/autoden/models/config/","title":"autoden.models.config","text":""},{"location":"reference/autoden/models/config/#autoden.models.config","title":"config","text":"<p>High level definition of CNN architectures.</p> <p>@author: Nicola VIGAN\u00d2, CEA-MEM, Grenoble, France</p> <p>Classes:</p> <ul> <li> <code>NetworkParams</code>           \u2013            <p>Abstract base class for storing network parameters.</p> </li> <li> <code>NetworkParamsDnCNN</code>           \u2013            <p>Store DnCNN parameters.</p> </li> <li> <code>NetworkParamsMSD</code>           \u2013            <p>Store MS-D net parameters.</p> </li> <li> <code>NetworkParamsUNet</code>           \u2013            <p>Store UNet parameters.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>create_network</code>             \u2013              <p>Create and return a neural network model based on the provided network configuration.</p> </li> <li> <code>create_optimizer</code>             \u2013              <p>Instantiates the desired optimizer for the given model.</p> </li> </ul>"},{"location":"reference/autoden/models/config/#autoden.models.config.NetworkParams","title":"NetworkParams","text":"<pre><code>NetworkParams(n_features: int, n_channels_in: int = 1, n_channels_out: int = 1)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for storing network parameters.</p> <p>Methods:</p> <ul> <li> <code>get_model</code>             \u2013              <p>Get the associated model with the selected parameters.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>def __init__(self, n_features: int, n_channels_in: int = 1, n_channels_out: int = 1) -&gt; None:\n    self.n_channels_in = n_channels_in\n    self.n_channels_out = n_channels_out\n    self.n_features = n_features\n</code></pre>"},{"location":"reference/autoden/models/config/#autoden.models.config.NetworkParams.get_model","title":"get_model  <code>abstractmethod</code>","text":"<pre><code>get_model(device: str = 'cuda' if is_available() else 'cpu') -&gt; Module\n</code></pre> <p>Get the associated model with the selected parameters.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>The device that the the model should run on, by default \"cuda\" if cuda is available, otherwise \"cpu\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Module</code>           \u2013            <p>The model.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>@abstractmethod\ndef get_model(self, device: str = \"cuda\" if is_cuda_available() else \"cpu\") -&gt; Module:\n    \"\"\"Get the associated model with the selected parameters.\n\n    Parameters\n    ----------\n    device : str, optional\n        The device that the the model should run on, by default \"cuda\" if cuda is available, otherwise \"cpu\".\n\n    Returns\n    -------\n    Module\n        The model.\n    \"\"\"\n</code></pre>"},{"location":"reference/autoden/models/config/#autoden.models.config.NetworkParamsDnCNN","title":"NetworkParamsDnCNN","text":"<pre><code>NetworkParamsDnCNN(n_channels_in: int = 1, n_channels_out: int = 1, n_layers: int = 20, n_features: int = 64)\n</code></pre> <p>               Bases: <code>NetworkParams</code></p> <p>Store DnCNN parameters.</p> <p>Parameters:</p> <ul> <li> <code>n_channels_in</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of input channels. Default is 1.</p> </li> <li> <code>n_channels_out</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of output channels. Default is 1.</p> </li> <li> <code>n_layers</code>               (<code>int</code>, default:                   <code>20</code> )           \u2013            <p>Number of layers. Default is 20.</p> </li> <li> <code>n_features</code>               (<code>int</code>, default:                   <code>64</code> )           \u2013            <p>Number of features. Default is 64.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>get_model</code>             \u2013              <p>Get a DnCNN model with the selected parameters.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>def __init__(self, n_channels_in: int = 1, n_channels_out: int = 1, n_layers: int = 20, n_features: int = 64) -&gt; None:\n    \"\"\"Initialize the DnCNN network parameters definition.\n\n    Parameters\n    ----------\n    n_channels_in : int, optional\n        Number of input channels. Default is 1.\n    n_channels_out : int, optional\n        Number of output channels. Default is 1.\n    n_layers : int, optional\n        Number of layers. Default is 20.\n    n_features : int, optional\n        Number of features. Default is 64.\n    \"\"\"\n    super().__init__(n_features=n_features, n_channels_in=n_channels_in, n_channels_out=n_channels_out)\n    self.n_layers = n_layers\n</code></pre>"},{"location":"reference/autoden/models/config/#autoden.models.config.NetworkParamsDnCNN.get_model","title":"get_model","text":"<pre><code>get_model(device: str = 'cuda' if is_available() else 'cpu') -&gt; Module\n</code></pre> <p>Get a DnCNN model with the selected parameters.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>The device that the the model should run on, by default \"cuda\" if cuda is available, otherwise \"cpu\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Module</code>           \u2013            <p>The DnCNN model.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>def get_model(self, device: str = \"cuda\" if is_cuda_available() else \"cpu\") -&gt; Module:\n    \"\"\"Get a DnCNN model with the selected parameters.\n\n    Parameters\n    ----------\n    device : str, optional\n        The device that the the model should run on, by default \"cuda\" if cuda is available, otherwise \"cpu\".\n\n    Returns\n    -------\n    Module\n        The DnCNN model.\n    \"\"\"\n    return DnCNN(\n        n_channels_in=self.n_channels_in,\n        n_channels_out=self.n_channels_out,\n        n_layers=self.n_layers,\n        n_features=self.n_features,\n        device=device,\n    )\n</code></pre>"},{"location":"reference/autoden/models/config/#autoden.models.config.NetworkParamsMSD","title":"NetworkParamsMSD","text":"<pre><code>NetworkParamsMSD(n_channels_in: int = 1, n_channels_out: int = 1, n_layers: int = 12, n_features: int = 1, dilations: Sequence[int] | NDArray[integer] = arange(1, 4), use_dilations: bool = True)\n</code></pre> <p>               Bases: <code>NetworkParams</code></p> <p>Store MS-D net parameters.</p> <p>Parameters:</p> <ul> <li> <code>n_channels_in</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of input channels, by default 1.</p> </li> <li> <code>n_channels_out</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of output channels, by default 1.</p> </li> <li> <code>n_layers</code>               (<code>int</code>, default:                   <code>12</code> )           \u2013            <p>Number of layers in the network, by default 12.</p> </li> <li> <code>n_features</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of features, by default 1.</p> </li> <li> <code>dilations</code>               (<code>Sequence[int] | NDArray[integer]</code>, default:                   <code>arange(1, 4)</code> )           \u2013            <p>Dilation values for the network, by default np.arange(1, 4).</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>get_model</code>             \u2013              <p>Get a MS-D net model with the selected parameters.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>def __init__(\n    self,\n    n_channels_in: int = 1,\n    n_channels_out: int = 1,\n    n_layers: int = 12,\n    n_features: int = 1,\n    dilations: Sequence[int] | NDArray[np.integer] = np.arange(1, 4),\n    use_dilations: bool = True,\n) -&gt; None:\n    \"\"\"Initialize the MS-D network parameters definition.\n\n    Parameters\n    ----------\n    n_channels_in : int, optional\n        Number of input channels, by default 1.\n    n_channels_out : int, optional\n        Number of output channels, by default 1.\n    n_layers : int, optional\n        Number of layers in the network, by default 12.\n    n_features : int, optional\n        Number of features, by default 1.\n    dilations : Sequence[int] | NDArray[np.integer], optional\n        Dilation values for the network, by default np.arange(1, 4).\n    \"\"\"\n    super().__init__(n_features=n_features, n_channels_in=n_channels_in, n_channels_out=n_channels_out)\n    self.n_layers = n_layers\n    self.dilations = dilations\n    self.use_dilations = use_dilations\n</code></pre>"},{"location":"reference/autoden/models/config/#autoden.models.config.NetworkParamsMSD.get_model","title":"get_model","text":"<pre><code>get_model(device: str = 'cuda' if is_available() else 'cpu') -&gt; Module\n</code></pre> <p>Get a MS-D net model with the selected parameters.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>The device that the the model should run on, by default \"cuda\" if cuda is available, otherwise \"cpu\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Module</code>           \u2013            <p>The model.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>def get_model(self, device: str = \"cuda\" if is_cuda_available() else \"cpu\") -&gt; Module:\n    \"\"\"Get a MS-D net model with the selected parameters.\n\n    Parameters\n    ----------\n    device : str, optional\n        The device that the the model should run on, by default \"cuda\" if cuda is available, otherwise \"cpu\".\n\n    Returns\n    -------\n    Module\n        The model.\n    \"\"\"\n    return MSDnet(\n        self.n_channels_in,\n        self.n_channels_out,\n        n_layers=self.n_layers,\n        n_features=self.n_features,\n        dilations=list(self.dilations),\n        device=device,\n        use_dilations=not self.use_dilations,\n    )\n</code></pre>"},{"location":"reference/autoden/models/config/#autoden.models.config.NetworkParamsUNet","title":"NetworkParamsUNet","text":"<pre><code>NetworkParamsUNet(n_channels_in: int = 1, n_channels_out: int = 1, n_levels: int = DEFAULT_LEVELS, n_features: int = DEFAULT_FEATURES, n_channels_skip: int | None = None, bilinear: bool = True, pad_mode: str = 'replicate')\n</code></pre> <p>               Bases: <code>NetworkParams</code></p> <p>Store UNet parameters.</p> <p>Parameters:</p> <ul> <li> <code>n_channels_in</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of input channels. Default is 1.</p> </li> <li> <code>n_channels_out</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of output channels. Default is 1.</p> </li> <li> <code>n_levels</code>               (<code>int</code>, default:                   <code>DEFAULT_LEVELS</code> )           \u2013            <p>Number of levels in the UNet. Default is 3.</p> </li> <li> <code>n_features</code>               (<code>int</code>, default:                   <code>DEFAULT_FEATURES</code> )           \u2013            <p>Number of features in the UNet. Default is 32.</p> </li> <li> <code>n_channels_skip</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of skip connections channels. Default is None.</p> </li> <li> <code>bilinear</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to use bilinear interpolation. Default is True.</p> </li> <li> <code>pad_mode</code>               (<code>str</code>, default:                   <code>'replicate'</code> )           \u2013            <p>Padding mode for convolutional layers. Default is \"replicate\".</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>get_model</code>             \u2013              <p>Get a U-net model with the selected parameters.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>def __init__(\n    self,\n    n_channels_in: int = 1,\n    n_channels_out: int = 1,\n    n_levels: int = DEFAULT_LEVELS,\n    n_features: int = DEFAULT_FEATURES,\n    n_channels_skip: int | None = None,\n    bilinear: bool = True,\n    pad_mode: str = \"replicate\",\n) -&gt; None:\n    \"\"\"Initialize the UNet network parameters definition.\n\n    Parameters\n    ----------\n    n_channels_in : int, optional\n        Number of input channels. Default is 1.\n    n_channels_out : int, optional\n        Number of output channels. Default is 1.\n    n_levels : int, optional\n        Number of levels in the UNet. Default is 3.\n    n_features : int, optional\n        Number of features in the UNet. Default is 32.\n    n_channels_skip : int, optional\n        Number of skip connections channels. Default is None.\n    bilinear : bool, optional\n        Whether to use bilinear interpolation. Default is True.\n    pad_mode : str, optional\n        Padding mode for convolutional layers. Default is \"replicate\".\n    \"\"\"\n    super().__init__(n_features=n_features, n_channels_in=n_channels_in, n_channels_out=n_channels_out)\n    self.n_levels = n_levels\n    self.n_channels_skip = n_channels_skip\n    self.bilinear = bilinear\n    self.pad_mode = pad_mode\n</code></pre>"},{"location":"reference/autoden/models/config/#autoden.models.config.NetworkParamsUNet.get_model","title":"get_model","text":"<pre><code>get_model(device: str = 'cuda' if is_available() else 'cpu') -&gt; Module\n</code></pre> <p>Get a U-net model with the selected parameters.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>The device that the the model should run on, by default \"cuda\" if cuda is available, otherwise \"cpu\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Module</code>           \u2013            <p>The U-net model.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>def get_model(self, device: str = \"cuda\" if is_cuda_available() else \"cpu\") -&gt; Module:\n    \"\"\"Get a U-net model with the selected parameters.\n\n    Parameters\n    ----------\n    device : str, optional\n        The device that the the model should run on, by default \"cuda\" if cuda is available, otherwise \"cpu\".\n\n    Returns\n    -------\n    Module\n        The U-net model.\n    \"\"\"\n    return UNet(\n        n_channels_in=self.n_channels_in,\n        n_channels_out=self.n_channels_out,\n        n_features=self.n_features,\n        n_levels=self.n_levels,\n        n_channels_skip=self.n_channels_skip,\n        bilinear=self.bilinear,\n        pad_mode=self.pad_mode,\n        device=device,\n    )\n</code></pre>"},{"location":"reference/autoden/models/config/#autoden.models.config.create_network","title":"create_network","text":"<pre><code>create_network(model: str | NetworkParams | Mapping | Module, state_dict: Mapping | None = None, device: str = 'cuda' if is_available() else 'cpu') -&gt; Module\n</code></pre> <p>Create and return a neural network model based on the provided network configuration.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str | NetworkParams | Mapping | Module</code>)           \u2013            <p>The network configuration. It can be a string specifying the network type, an instance of <code>NetworkParams</code>, or an already instantiated <code>Module</code>. If a string is provided, it must be one of the supported network types: \"msd\", \"unet\", or \"dncnn\".</p> </li> <li> <code>state_dict</code>               (<code>Mapping | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary containing the state dictionary of the model. If provided, the model's parameters will be loaded from this dictionary. Default is None.</p> </li> <li> <code>device</code>               (<code>str</code>, default:                   <code>'cuda' if is_available() else 'cpu'</code> )           \u2013            <p>The device to which the model should be moved. Default is \"cuda\" if CUDA is available, otherwise \"cpu\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Module</code>           \u2013            <p>The created neural network model.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the provided network name is invalid or the network type is not supported.</p> </li> </ul> Notes <p>The function supports the following network types: - \"msd\": Multi-Scale Dense Network. - \"unet\": U-Net. - \"dncnn\": Denoising Convolutional Neural Network.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; net = create_network(\"unet\")\n&gt;&gt;&gt; print(net)\nModel UNet - num. parameters: 1234567\n</code></pre> Source code in <code>src/autoden/models/config.py</code> <pre><code>def create_network(\n    model: str | NetworkParams | Mapping | Module,\n    state_dict: Mapping | None = None,\n    device: str = \"cuda\" if is_cuda_available() else \"cpu\",\n) -&gt; Module:\n    \"\"\"\n    Create and return a neural network model based on the provided network configuration.\n\n    Parameters\n    ----------\n    model : str | NetworkParams | Mapping | Module\n        The network configuration. It can be a string specifying the network type,\n        an instance of `NetworkParams`, or an already instantiated `Module`.\n        If a string is provided, it must be one of the supported network types:\n        \"msd\", \"unet\", or \"dncnn\".\n    state_dict : Mapping | None, optional\n        A dictionary containing the state dictionary of the model. If provided,\n        the model's parameters will be loaded from this dictionary. Default is None.\n    device : str, optional\n        The device to which the model should be moved. Default is \"cuda\" if CUDA is available,\n        otherwise \"cpu\".\n\n    Returns\n    -------\n    Module\n        The created neural network model.\n\n    Raises\n    ------\n    ValueError\n        If the provided network name is invalid or the network type is not supported.\n\n    Notes\n    -----\n    The function supports the following network types:\n    - \"msd\": Multi-Scale Dense Network.\n    - \"unet\": U-Net.\n    - \"dncnn\": Denoising Convolutional Neural Network.\n\n    Examples\n    --------\n    &gt;&gt;&gt; net = create_network(\"unet\")\n    &gt;&gt;&gt; print(net)\n    Model UNet - num. parameters: 1234567\n    \"\"\"\n    if isinstance(model, Mapping):\n        if (\"model_class\", \"state_dict\") not in model:\n            raise ValueError(\"Malformed model state dictionary. Expected two mandatory fields: 'model_class' and 'state_dict'\")\n        state_dict = model[\"state_dict\"]\n        model = model[\"model_class\"]\n\n    if isinstance(model, str):\n        if model.lower() in (\"msd\", MSDnet.__name__.lower()):\n            model = NetworkParamsMSD()\n        elif model.lower() == UNet.__name__.lower():\n            model = NetworkParamsUNet()\n        elif model.lower() == DnCNN.__name__.lower():\n            model = NetworkParamsDnCNN()\n        else:\n            raise ValueError(f\"Invalid model name: {model}\")\n\n    if isinstance(model, NetworkParams):\n        net = model.get_model(device)\n    elif isinstance(model, Module):\n        net = model.to(device=device)\n    else:\n        raise ValueError(f\"Invalid model type: {type(model)}\")\n\n    if state_dict is not None:\n        net.load_state_dict(state_dict)\n        net.to(device)  # Needed to ensure that the model lives in the correct device\n\n    print(f\"Model {net.__class__.__name__} - num. parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad)}\")\n    return net\n</code></pre>"},{"location":"reference/autoden/models/config/#autoden.models.config.create_optimizer","title":"create_optimizer","text":"<pre><code>create_optimizer(network: Module, algo: str = 'adam', learning_rate: float = 0.001, weight_decay: float = 0.01, optim_state: Mapping | None = None) -&gt; Optimizer\n</code></pre> <p>Instantiates the desired optimizer for the given model.</p> <p>Parameters:</p> <ul> <li> <code>network</code>               (<code>Module</code>)           \u2013            <p>The network to train.</p> </li> <li> <code>algo</code>               (<code>str</code>, default:                   <code>'adam'</code> )           \u2013            <p>The requested optimizer, by default \"adam\".</p> </li> <li> <code>learning_rate</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>The desired learning rate, by default 1e-3.</p> </li> <li> <code>weight_decay</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>The desired weight decay, by default 1e-2.</p> </li> <li> <code>optim_state</code>               (<code>Mapping | None</code>, default:                   <code>None</code> )           \u2013            <p>The state dictionary for the optimizer, by default None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Optimizer</code>           \u2013            <p>The chosen optimizer.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unsupported algorithm is requested.</p> </li> </ul> Source code in <code>src/autoden/models/config.py</code> <pre><code>def create_optimizer(\n    network: Module,\n    algo: str = \"adam\",\n    learning_rate: float = 1e-3,\n    weight_decay: float = 1e-2,\n    optim_state: Mapping | None = None,\n) -&gt; pt.optim.Optimizer:\n    \"\"\"Instantiates the desired optimizer for the given model.\n\n    Parameters\n    ----------\n    network : torch.nn.Module\n        The network to train.\n    algo : str, optional\n        The requested optimizer, by default \"adam\".\n    learning_rate : float, optional\n        The desired learning rate, by default 1e-3.\n    weight_decay : float, optional\n        The desired weight decay, by default 1e-2.\n    optim_state : Mapping | None, optional\n        The state dictionary for the optimizer, by default None.\n\n    Returns\n    -------\n    torch.optim.Optimizer\n        The chosen optimizer.\n\n    Raises\n    ------\n    ValueError\n        If an unsupported algorithm is requested.\n    \"\"\"\n    if algo.lower() == \"adam\":\n        optimizer = pt.optim.AdamW(network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    elif algo.lower() == \"sgd\":\n        optimizer = pt.optim.SGD(network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    elif algo.lower() == \"rmsprop\":\n        optimizer = pt.optim.RMSprop(network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    elif algo.lower() == \"lbfgs\":\n        optimizer = pt.optim.LBFGS(network.parameters(), lr=learning_rate, max_iter=10000, history_size=50)\n    else:\n        raise ValueError(f\"Unknown algorithm: {algo}\")\n\n    if optim_state is not None:\n        optimizer.load_state_dict(dict(**optim_state))\n\n    return optimizer\n</code></pre>"},{"location":"reference/autoden/models/dncnn/","title":"autoden.models.dncnn","text":""},{"location":"reference/autoden/models/dncnn/#autoden.models.dncnn","title":"dncnn","text":"<p>Classes:</p> <ul> <li> <code>ConvBlock</code>           \u2013            <p>Convolution block: conv =&gt; BN =&gt; act.</p> </li> <li> <code>DnCNN</code>           \u2013            <p>Implementation of the DnCNN architecture from [1].</p> </li> </ul>"},{"location":"reference/autoden/models/dncnn/#autoden.models.dncnn.ConvBlock","title":"ConvBlock","text":"<pre><code>ConvBlock(in_ch: int, out_ch: int, kernel_size: int, pad_mode: str = 'replicate', last_block: bool = False)\n</code></pre> <p>               Bases: <code>Sequential</code></p> <p>Convolution block: conv =&gt; BN =&gt; act.</p> Source code in <code>src/autoden/models/dncnn.py</code> <pre><code>def __init__(self, in_ch: int, out_ch: int, kernel_size: int, pad_mode: str = \"replicate\", last_block: bool = False):\n    pad_size = (kernel_size - 1) // 2\n    if last_block:\n        post_conv = []\n    else:\n        post_conv = [nn.BatchNorm2d(out_ch), nn.LeakyReLU(0.2, inplace=True)]\n    super().__init__(\n        nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=pad_size, padding_mode=pad_mode, bias=False),\n        *post_conv,\n    )\n</code></pre>"},{"location":"reference/autoden/models/dncnn/#autoden.models.dncnn.DnCNN","title":"DnCNN","text":"<pre><code>DnCNN(n_channels_in: int, n_channels_out: int, n_layers: int = 20, n_features: int = 32, kernel_size: int = 3, pad_mode: str = 'replicate', device: str = 'cuda' if is_available() else 'cpu')\n</code></pre> <p>               Bases: <code>Sequential</code></p> <p>Implementation of the DnCNN architecture from [1].</p> <p>[1] Zhang, et al., \"Beyond a Gaussian denoiser: Residual learning of deep CNN     for image denoising,\" IEEE Trans. on Image Processing, 2017.</p> Source code in <code>src/autoden/models/dncnn.py</code> <pre><code>def __init__(\n    self,\n    n_channels_in: int,\n    n_channels_out: int,\n    n_layers: int = 20,\n    n_features: int = 32,\n    kernel_size: int = 3,\n    pad_mode: str = \"replicate\",\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n):\n    # From zhang-2017-beyon-gauss-denois:\n    #\n    #  Thus, for Gaussian denoising with a certain noise level, we\n    #  set the receptive field size of DnCNN to 35 \u00d7 35 with the\n    #  corresponding depth of 17. For other general image denoising\n    #  tasks, we adopt a larger receptive field and set the depth\n    #  to be 20.\n    #\n    # Hence, we set the standard depth to 20.\n    layers = [\n        ConvBlock(\n            n_channels_in if i_l == 0 else n_features,\n            n_channels_out if i_l == (n_layers - 1) else n_features,\n            kernel_size=kernel_size,\n            pad_mode=pad_mode,\n            last_block=(i_l == (n_layers - 1)),\n        )\n        for i_l in range(n_layers)\n    ]\n\n    super().__init__(*layers)\n    self.n_ch_in = n_channels_in\n    self.n_ch_out = n_channels_out\n    self.n_layers = n_layers\n    self.device = device\n\n    self.to(self.device)\n</code></pre>"},{"location":"reference/autoden/models/msd/","title":"autoden.models.msd","text":""},{"location":"reference/autoden/models/msd/#autoden.models.msd","title":"msd","text":"<p>Module implementing MS-D net.</p> <p>Classes:</p> <ul> <li> <code>DilatedConvBlock</code>           \u2013            <p>Dilated convolution block (dilated_conv =&gt; BN =&gt; ReLU).</p> </li> <li> <code>MSDDilBlock</code>           \u2013            <p>MS-D Block containing the sequence of dilated convolutional layers.</p> </li> <li> <code>MSDSampBlock</code>           \u2013            <p>MS-D Block containing the sequence of dilated convolutional layers.</p> </li> <li> <code>MSDnet</code>           \u2013            <p>Simple MS-D net implementation.</p> </li> <li> <code>SamplingConvBlock</code>           \u2013            <p>Down-sampling convolution module (down-samp =&gt; conv =&gt; BN =&gt; ReLU =&gt; up-samp).</p> </li> </ul>"},{"location":"reference/autoden/models/msd/#autoden.models.msd.DilatedConvBlock","title":"DilatedConvBlock","text":"<pre><code>DilatedConvBlock(in_ch: int, out_ch: int, dilation: int = 1, pad_mode: str = 'replicate')\n</code></pre> <p>               Bases: <code>Sequential</code></p> <p>Dilated convolution block (dilated_conv =&gt; BN =&gt; ReLU).</p> Source code in <code>src/autoden/models/msd.py</code> <pre><code>def __init__(self, in_ch: int, out_ch: int, dilation: int = 1, pad_mode: str = \"replicate\") -&gt; None:\n    super().__init__(\n        nn.Conv2d(in_ch, out_ch, 3, padding=dilation, dilation=dilation, padding_mode=pad_mode),\n        nn.BatchNorm2d(out_ch),\n        nn.LeakyReLU(0.2, inplace=True),\n    )\n</code></pre>"},{"location":"reference/autoden/models/msd/#autoden.models.msd.MSDDilBlock","title":"MSDDilBlock","text":"<pre><code>MSDDilBlock(n_channels_in: int, n_features: int, n_layers: int, dilations: Sequence[int])\n</code></pre> <p>               Bases: <code>Module</code></p> <p>MS-D Block containing the sequence of dilated convolutional layers.</p> Source code in <code>src/autoden/models/msd.py</code> <pre><code>def __init__(self, n_channels_in: int, n_features: int, n_layers: int, dilations: Sequence[int]) -&gt; None:\n    super().__init__()\n    self.n_features = n_features\n    self.n_layers = n_layers\n    self.dilations = dilations\n    convs = [\n        DilatedConvBlock(n_channels_in + n_features * ii, n_features, dilation=self._layer_dilation(ii))\n        for ii in range(n_layers)\n    ]\n    self.convs = nn.ModuleList(convs)\n    self.n_ch_in = n_channels_in\n</code></pre>"},{"location":"reference/autoden/models/msd/#autoden.models.msd.MSDSampBlock","title":"MSDSampBlock","text":"<pre><code>MSDSampBlock(n_channels_in: int, n_features: int, n_layers: int, dilations: Sequence[int])\n</code></pre> <p>               Bases: <code>Module</code></p> <p>MS-D Block containing the sequence of dilated convolutional layers.</p> Source code in <code>src/autoden/models/msd.py</code> <pre><code>def __init__(self, n_channels_in: int, n_features: int, n_layers: int, dilations: Sequence[int]) -&gt; None:\n    super().__init__()\n    self.n_features = n_features\n    self.n_layers = n_layers\n    self.dilations = dilations\n    convs = [\n        SamplingConvBlock(n_channels_in + n_features * ii, n_features, samp_factor=self._layer_sampling(ii))\n        for ii in range(n_layers)\n    ]\n    self.convs = nn.ModuleList(convs)\n    self.n_ch_in = n_channels_in\n</code></pre>"},{"location":"reference/autoden/models/msd/#autoden.models.msd.MSDnet","title":"MSDnet","text":"<pre><code>MSDnet(n_channels_in: int = 1, n_channels_out: int = 1, n_layers: int = 12, n_features: int = 1, dilations: Sequence[int] = [1, 2, 3, 4], device: str = 'cuda' if is_available() else 'cpu', use_dilations: bool = True)\n</code></pre> <p>               Bases: <code>Module</code></p> <p>Simple MS-D net implementation.</p> Source code in <code>src/autoden/models/msd.py</code> <pre><code>def __init__(\n    self,\n    n_channels_in: int = 1,\n    n_channels_out: int = 1,\n    n_layers: int = 12,\n    n_features: int = 1,\n    dilations: Sequence[int] = [1, 2, 3, 4],\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n    use_dilations: bool = True,\n) -&gt; None:\n    super().__init__()\n    self.n_ch_in = n_channels_in\n    self.n_ch_out = n_channels_out\n    self.dilations = dilations\n    self.n_layers = n_layers\n    self.n_nodes = n_features\n    self.device = device\n\n    if use_dilations:\n        self.msd_block = MSDDilBlock(n_channels_in, n_features, n_layers, dilations)\n    else:\n        self.msd_block = MSDSampBlock(n_channels_in, n_features, n_layers, dilations)\n    self.outc = nn.Conv2d(n_channels_in + n_features * n_layers, n_channels_out, kernel_size=1)\n\n    self.to(self.device)\n</code></pre>"},{"location":"reference/autoden/models/msd/#autoden.models.msd.SamplingConvBlock","title":"SamplingConvBlock","text":"<pre><code>SamplingConvBlock(in_ch: int, out_ch: int, samp_factor: int = 1)\n</code></pre> <p>               Bases: <code>Sequential</code></p> <p>Down-sampling convolution module (down-samp =&gt; conv =&gt; BN =&gt; ReLU =&gt; up-samp).</p> Source code in <code>src/autoden/models/msd.py</code> <pre><code>def __init__(self, in_ch: int, out_ch: int, samp_factor: int = 1) -&gt; None:\n    if samp_factor &gt; 1:\n        pre = [nn.AvgPool2d(samp_factor)]\n        post = [nn.Upsample(scale_factor=samp_factor, mode=\"bilinear\", align_corners=True)]\n    else:\n        pre = post = []\n    super().__init__(\n        *pre, nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.LeakyReLU(0.2, inplace=True), *post\n    )\n</code></pre>"},{"location":"reference/autoden/models/param_utils/","title":"autoden.models.param_utils","text":""},{"location":"reference/autoden/models/param_utils/#autoden.models.param_utils","title":"param_utils","text":"<p>This module provides utility functions for handling PyTorch models, including optimization, parameter management, and gradient retrieval.</p> <p>Functions:     create_optimizer: Instantiates the desired optimizer for the given model.     get_num_parameters: Returns the number of trainable parameters in the model.     set_parameters: Sets the parameters of the model from a given array of values.     get_parameters: Gets the parameters of the model.     get_gradients: Gets the gradients of the model parameters.</p> <p>Functions:</p> <ul> <li> <code>fix_invalid_gradient_values</code>             \u2013              <p>Fixes invalid gradient values in the model's parameters.</p> </li> <li> <code>get_gradients</code>             \u2013              <p>Gets the gradients of the model parameters.</p> </li> <li> <code>get_num_parameters</code>             \u2013              <p>Returns the number of trainable parameters in the model.</p> </li> <li> <code>get_parameters</code>             \u2013              <p>Gets the parameters of the model.</p> </li> <li> <code>set_parameters</code>             \u2013              <p>Sets the parameters of the model from a given array of values.</p> </li> </ul>"},{"location":"reference/autoden/models/param_utils/#autoden.models.param_utils.fix_invalid_gradient_values","title":"fix_invalid_gradient_values","text":"<pre><code>fix_invalid_gradient_values(model: Module) -&gt; None\n</code></pre> <p>Fixes invalid gradient values in the model's parameters.</p> <p>This function iterates over all parameters of the given model and sets the gradient values to zero where they are not finite (i.e., NaN or infinity).</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The neural network model whose gradient values need to be fixed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>This function modifies the gradients in place and does not return anything.</p> </li> </ul> Source code in <code>src/autoden/models/param_utils.py</code> <pre><code>def fix_invalid_gradient_values(model: nn.Module) -&gt; None:\n    \"\"\"\n    Fixes invalid gradient values in the model's parameters.\n\n    This function iterates over all parameters of the given model and sets the\n    gradient values to zero where they are not finite (i.e., NaN or infinity).\n\n    Parameters\n    ----------\n    model : nn.Module\n        The neural network model whose gradient values need to be fixed.\n\n    Returns\n    -------\n    None\n        This function modifies the gradients in place and does not return anything.\n    \"\"\"\n    for pars in model.parameters():\n        if pars.grad is not None:\n            pars.grad[pt.logical_not(pt.isfinite(pars.grad))] = 0.0\n</code></pre>"},{"location":"reference/autoden/models/param_utils/#autoden.models.param_utils.get_gradients","title":"get_gradients","text":"<pre><code>get_gradients(model: Module, flatten: bool = True) -&gt; tuple[NDArray, Sequence[tuple[str, Sequence[int]]]]\n</code></pre> <p>Gets the gradients of the model parameters.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The model to get the gradients from.</p> </li> <li> <code>flatten</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, flattens the gradients, by default True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[NDArray, Sequence[tuple[str, Sequence[int]]]]</code>           \u2013            <p>A tuple containing the gradient values and their shapes.</p> </li> </ul> Source code in <code>src/autoden/models/param_utils.py</code> <pre><code>def get_gradients(model: nn.Module, flatten: bool = True) -&gt; tuple[NDArray, Sequence[tuple[str, Sequence[int]]]]:\n    \"\"\"Gets the gradients of the model parameters.\n\n    Parameters\n    ----------\n    model : torch.nn.Module\n        The model to get the gradients from.\n    flatten : bool, optional\n        If True, flattens the gradients, by default True.\n\n    Returns\n    -------\n    tuple[numpy.typing.NDArray, Sequence[tuple[str, Sequence[int]]]]\n        A tuple containing the gradient values and their shapes.\n    \"\"\"\n    grads = []\n    info = []\n    for name, params in model.named_parameters():\n        if params.grad is not None:\n            g1 = params.grad.view(-1)\n            grad = g1.detach().cpu().numpy().copy()\n            if flatten:\n                grad = grad.flatten()\n            grads.append(grad)\n            info.append((name, [*params.shape]))\n    return np.concatenate(grads), info\n</code></pre>"},{"location":"reference/autoden/models/param_utils/#autoden.models.param_utils.get_num_parameters","title":"get_num_parameters","text":"<pre><code>get_num_parameters(model: Module, verbose: bool = False) -&gt; int\n</code></pre> <p>Returns the number of trainable parameters in the model.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The model to count the parameters for.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, prints the number of parameters, by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>The number of trainable parameters.</p> </li> </ul> Source code in <code>src/autoden/models/param_utils.py</code> <pre><code>def get_num_parameters(model: nn.Module, verbose: bool = False) -&gt; int:\n    \"\"\"Returns the number of trainable parameters in the model.\n\n    Parameters\n    ----------\n    model : torch.nn.Module\n        The model to count the parameters for.\n    verbose : bool, optional\n        If True, prints the number of parameters, by default False.\n\n    Returns\n    -------\n    int\n        The number of trainable parameters.\n    \"\"\"\n    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    if verbose:\n        print(f\"Model {model.__class__.__name__} - num. parameters: {num_params}\")\n    return num_params\n</code></pre>"},{"location":"reference/autoden/models/param_utils/#autoden.models.param_utils.get_parameters","title":"get_parameters","text":"<pre><code>get_parameters(model: Module, parameter_type: str | None = None, filter_params: bool = True) -&gt; tuple[NDArray, Sequence[tuple[str, Sequence[int]]]]\n</code></pre> <p>Gets the parameters of the model.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The model to get the parameters from.</p> </li> <li> <code>parameter_type</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The type of parameters to filter, by default None.</p> </li> <li> <code>filter_params</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, filters the parameters based on the parameter_type, by default True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[NDArray, Sequence[tuple[str, Sequence[int]]]]</code>           \u2013            <p>A tuple containing the parameter values and their shapes.</p> </li> </ul> Source code in <code>src/autoden/models/param_utils.py</code> <pre><code>def get_parameters(\n    model: nn.Module, parameter_type: str | None = None, filter_params: bool = True\n) -&gt; tuple[NDArray, Sequence[tuple[str, Sequence[int]]]]:\n    \"\"\"Gets the parameters of the model.\n\n    Parameters\n    ----------\n    model : torch.nn.Module\n        The model to get the parameters from.\n    parameter_type : str | None, optional\n        The type of parameters to filter, by default None.\n    filter_params : bool, optional\n        If True, filters the parameters based on the parameter_type, by default True.\n\n    Returns\n    -------\n    tuple[numpy.typing.NDArray, Sequence[tuple[str, Sequence[int]]]]\n        A tuple containing the parameter values and their shapes.\n    \"\"\"\n    vals = []\n    info = []\n    for name, params in model.named_parameters():\n        p1 = params.view(-1)\n        if parameter_type is None or name.split(\".\")[-1] == parameter_type.lower():\n            vals.append(p1.detach().cpu().numpy().copy().flatten())\n            info.append((name, [*params.shape]))\n        elif not filter_params:\n            vals.append(np.zeros_like(p1.detach().cpu().numpy()).flatten())\n            info.append((name, [*params.shape]))\n    return np.concatenate(vals), info\n</code></pre>"},{"location":"reference/autoden/models/param_utils/#autoden.models.param_utils.set_parameters","title":"set_parameters","text":"<pre><code>set_parameters(model: Module, values: NDArray, info: Sequence[tuple[str, Sequence[int]]]) -&gt; None\n</code></pre> <p>Sets the parameters of the model from a given array of values.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The model to set the parameters for.</p> </li> <li> <code>values</code>               (<code>NDArray</code>)           \u2013            <p>The array of parameter values.</p> </li> <li> <code>info</code>               (<code>Sequence[tuple[str, Sequence[int]]]</code>)           \u2013            <p>Information about the parameter names and shapes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the length of the values array does not match the total number of parameters.</p> </li> </ul> Source code in <code>src/autoden/models/param_utils.py</code> <pre><code>def set_parameters(model: nn.Module, values: NDArray, info: Sequence[tuple[str, Sequence[int]]]) -&gt; None:\n    \"\"\"Sets the parameters of the model from a given array of values.\n\n    Parameters\n    ----------\n    model : torch.nn.Module\n        The model to set the parameters for.\n    values : numpy.typing.NDArray\n        The array of parameter values.\n    info : Sequence[tuple[str, Sequence[int]]]\n        Information about the parameter names and shapes.\n\n    Raises\n    ------\n    ValueError\n        If the length of the values array does not match the total number of parameters.\n    \"\"\"\n    if len(values) != sum([np.prod(v) for _, v in info]):\n        raise ValueError(\"Inconsistent length of values array and parameters shapes\")\n    state_dict = model.state_dict()\n    params_start = 0\n    for name, p_shape in info:\n        params_end = params_start + np.prod(p_shape)\n        state_dict[name][:] = pt.tensor(values[params_start:params_end].reshape(p_shape))\n        params_start = params_end\n</code></pre>"},{"location":"reference/autoden/models/unet/","title":"autoden.models.unet","text":""},{"location":"reference/autoden/models/unet/#autoden.models.unet","title":"unet","text":"<p>Implementation of a flexible U-net.</p> <p>Originally inspired by: https://github.com/milesial/Pytorch-UNet</p> <p>Classes:</p> <ul> <li> <code>ConvBlock</code>           \u2013            <p>Convolution block: conv =&gt; BN =&gt; act.</p> </li> <li> <code>DoubleConv</code>           \u2013            <p>Double convolution (conv =&gt; BN =&gt; ReLU) * 2.</p> </li> <li> <code>DownBlock</code>           \u2013            <p>Down-scaling block.</p> </li> <li> <code>UNet</code>           \u2013            <p>U-net model.</p> </li> <li> <code>UpBlock</code>           \u2013            <p>Up-scaling block.</p> </li> </ul>"},{"location":"reference/autoden/models/unet/#autoden.models.unet.ConvBlock","title":"ConvBlock","text":"<pre><code>ConvBlock(in_ch: int, out_ch: int, kernel_size: int, stride: int = 1, dilation: int = 1, pad_mode: str = 'replicate', residual: bool = False, bias: bool = True, last_block: bool = False)\n</code></pre> <p>               Bases: <code>Sequential</code></p> <p>Convolution block: conv =&gt; BN =&gt; act.</p> Source code in <code>src/autoden/models/unet.py</code> <pre><code>def __init__(\n    self,\n    in_ch: int,\n    out_ch: int,\n    kernel_size: int,\n    stride: int = 1,\n    dilation: int = 1,\n    pad_mode: str = \"replicate\",\n    residual: bool = False,\n    bias: bool = True,\n    last_block: bool = False,\n):\n    pad_size = (kernel_size - 1) // 2 + (dilation - 1)\n    if last_block:\n        post_conv = []\n    else:\n        post_conv = [nn.BatchNorm2d(out_ch), nn.LeakyReLU(0.2, inplace=True)]\n    super().__init__(\n        nn.Conv2d(\n            in_ch,\n            out_ch,\n            kernel_size=kernel_size,\n            stride=stride,\n            dilation=dilation,\n            padding=pad_size,\n            padding_mode=pad_mode,\n            bias=bias,\n        ),\n        *post_conv,\n    )\n    if residual and in_ch != out_ch:\n        print(f\"Warning: Residual connections not available when {in_ch=} is different from {out_ch=}\")\n        residual = False\n    self.residual = residual\n</code></pre>"},{"location":"reference/autoden/models/unet/#autoden.models.unet.DoubleConv","title":"DoubleConv","text":"<pre><code>DoubleConv(in_ch: int, out_ch: int, pad_mode: str = 'replicate')\n</code></pre> <p>               Bases: <code>Sequential</code></p> <p>Double convolution (conv =&gt; BN =&gt; ReLU) * 2.</p> Source code in <code>src/autoden/models/unet.py</code> <pre><code>def __init__(self, in_ch: int, out_ch: int, pad_mode: str = \"replicate\"):\n    super().__init__(\n        ConvBlock(in_ch, out_ch, kernel_size=3, pad_mode=pad_mode),\n        ConvBlock(out_ch, out_ch, kernel_size=1),\n    )\n</code></pre>"},{"location":"reference/autoden/models/unet/#autoden.models.unet.DownBlock","title":"DownBlock","text":"<pre><code>DownBlock(in_ch: int, out_ch: int, bilinear: bool = True, pad_mode: str = 'replicate')\n</code></pre> <p>               Bases: <code>Sequential</code></p> <p>Down-scaling block.</p> Source code in <code>src/autoden/models/unet.py</code> <pre><code>def __init__(self, in_ch: int, out_ch: int, bilinear: bool = True, pad_mode: str = \"replicate\"):\n    if bilinear:\n        down_block = [nn.AvgPool2d(2)]\n    else:\n        down_block = [ConvBlock(in_ch, in_ch, kernel_size=2, stride=2)]\n    super().__init__(\n        *down_block,\n        DoubleConv(in_ch, out_ch, pad_mode=pad_mode),\n    )\n    self.pad_mode = pad_mode.lower()\n</code></pre>"},{"location":"reference/autoden/models/unet/#autoden.models.unet.UNet","title":"UNet","text":"<pre><code>UNet(n_channels_in: int, n_channels_out: int, n_features: int = 32, n_levels: int = 3, n_channels_skip: int | None = None, bilinear: bool = True, pad_mode: str = 'replicate', device: str = 'cuda' if is_available() else 'cpu', verbose: bool = False)\n</code></pre> <p>               Bases: <code>Module</code></p> <p>U-net model.</p> Source code in <code>src/autoden/models/unet.py</code> <pre><code>def __init__(\n    self,\n    n_channels_in: int,\n    n_channels_out: int,\n    n_features: int = 32,\n    n_levels: int = 3,\n    n_channels_skip: int | None = None,\n    bilinear: bool = True,\n    pad_mode: str = \"replicate\",\n    device: str = \"cuda\" if pt.cuda.is_available() else \"cpu\",\n    verbose: bool = False,\n):\n    super().__init__()\n    self.n_ch_in = n_channels_in\n    self.n_ch_out = n_channels_out\n    self.device = device\n\n    if pad_mode.lower() not in PAD_MODES:\n        raise ValueError(f\"Padding mode {pad_mode} should be one of {PAD_MODES}\")\n    self.pad_mode = pad_mode.lower()\n\n    encoder, decoder = _compute_architecture(\n        n_levels=n_levels, n_features=n_features, n_skip=n_channels_skip, verbose=verbose\n    )\n\n    self.in_layer = DoubleConv(n_channels_in, n_features, pad_mode=pad_mode)\n    self.encoder_layers = nn.ModuleList([DownBlock(*lvl, bilinear=bilinear, pad_mode=pad_mode) for lvl in encoder])\n    self.decoder_layers = nn.ModuleList([UpBlock(*lvl, bilinear=bilinear, pad_mode=pad_mode) for lvl in decoder])\n    self.out_layer = ConvBlock(n_features, n_channels_out, kernel_size=1, last_block=True, pad_mode=pad_mode)\n\n    if verbose:\n        print(\n            f\"Model {self.__class__.__name__} - \"\n            f\"num. parameters: {sum(p.numel() for p in self.parameters() if p.requires_grad)}\"\n        )\n    self.to(self.device)\n</code></pre>"},{"location":"reference/autoden/models/unet/#autoden.models.unet.UpBlock","title":"UpBlock","text":"<pre><code>UpBlock(in_ch: int, skip_ch: int | None, out_ch: int, bilinear: bool = False, pad_mode: str = 'replicate')\n</code></pre> <p>               Bases: <code>Module</code></p> <p>Up-scaling block.</p> Source code in <code>src/autoden/models/unet.py</code> <pre><code>def __init__(self, in_ch: int, skip_ch: int | None, out_ch: int, bilinear: bool = False, pad_mode: str = \"replicate\"):\n    super().__init__()\n    self.skip_ch = skip_ch\n\n    # Bilinear up-sampling tends to give better results, and use fewer weights\n    if bilinear:\n        self.up_block = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n    else:\n        self.up_block = nn.ConvTranspose2d(in_ch, in_ch, kernel_size=2, stride=2)\n\n    if skip_ch is not None:\n        n_skip = skip_ch\n        if skip_ch &gt; 0:\n            self.skip_block = ConvBlock(in_ch, skip_ch, kernel_size=1)\n    else:\n        n_skip = in_ch\n\n    self.conv_block = DoubleConv(in_ch + n_skip, out_ch, pad_mode=pad_mode)\n</code></pre>"}]}